# CityPulse: Unified Smart City Urban Intelligence System
## Product Requirements Document (PRD)

# Overview
CityPulse is an agentic urban intelligence platform that transforms the overwhelming volume of real-time city data into actionable insights. The system addresses the critical challenge of data fragmentation in modern cities by continuously ingesting diverse urban data streams (traffic feeds, social media, IoT sensors, civic reports, citizen-submitted multimedia) and applying AI agents to synthesize, analyze, and visualize this information on a live, interactive dashboard.

**Problem Solved**: Cities generate massive volumes of disparate data that remain siloed, leading to reactive governance and missed opportunities for proactive city management. Citizens lack effective channels to participate in urban governance and receive timely, relevant information about their city.

**Target Users**:
- **Primary**: City authorities (planners, emergency responders, municipal officials)
- **Secondary**: Citizens (residents, commuters, business owners)

**Value Proposition**: CityPulse provides a "single pane of glass" view of city operations for authorities while empowering citizens with timely alerts and participatory reporting capabilities. The platform turns raw urban data into knowledge and actionable impact through automated AI processing and predictive analytics.

# Core Features

## Data Fusion & Synthesis
**What it does**: Continuously ingests and correlates data from multiple urban sources (social media, official feeds, IoT sensors, citizen reports) using Google Cloud Pub/Sub and Dataflow pipelines. BigQuery serves as the fusion layer, joining streams by location and time to create a unified urban data view.

**Why it's important**: Eliminates data silos that plague modern cities, enabling comprehensive situational awareness and evidence-based decision making.

**How it works**: Automated ETL processes clean, normalize, and geotag incoming data. AI agents correlate related events (e.g., linking traffic camera data with citizen complaints and social media posts about the same incident) and compute aggregate features like sentiment scores and traffic densities.

## Multimodal AI Processing & Agentic Workflows
**What it does**: Leverages Vertex AI's Gemini (multimodal LLM), Vision API, and Imagen to analyze text, images, and video content. AI agents autonomously execute complex workflows including summarization, classification, and alert generation.

**Why it's important**: Automates the overwhelming task of processing thousands of daily reports, images, and social media posts, allowing limited staff to manage city-wide monitoring effectively.

**How it works**: When a citizen uploads a photo of street flooding, Vision AI detects "waterlogging," Gemini generates a geo-tagged description, and agentic workflows group related reports, assess severity, and trigger appropriate alerts—all without human intervention.

## Predictive Analytics & Forecasting
**What it does**: Uses BigQuery ML and Vertex AI TimeSeries Insights to train models (ARIMA, LSTMs) on historical data for forecasting events like traffic surges, infrastructure failures, and weather-related incidents.

**Why it's important**: Enables proactive rather than reactive city management, allowing authorities to deploy resources before problems escalate.

**How it works**: RAG-powered agents analyze historical patterns and generate human-readable forecasts ("Pothole reports have risen 50% this month due to monsoon; recommend deploying crews to Ward 12"). Automated anomaly detection flags unusual patterns in real-time.

## Interactive Dashboard & Visualization
**What it does**: Provides a real-time interactive map (Google Maps SDK) with layered views including heatmaps, custom incident markers, live charts, and KPI gauges that update via Firestore subscriptions.

**Why it's important**: Delivers complex urban intelligence in an intuitive, actionable format for both technical and non-technical users.

**How it works**: Dense incidents form heatmap overlays, sentiment appears as color-coded zones, and Gemini-generated insights cards narrate complex data ("Traffic on Outer Ring Road eased 10% after rain cleared"). Custom visuals from Imagen enhance UI engagement.

## Social Sentiment & Trend Analysis
**What it does**: Continuously mines public social media, news feeds, and forums using NLP models to gauge public mood, track topic discussions, and identify emerging trends across neighborhoods.

**Why it's important**: Provides city authorities with citizen sentiment intelligence for policy decisions and helps identify issues before they escalate into larger problems.

**How it works**: Vertex AI models process social streams to compute sentiment scores and topic trends. Results are visualized as "mood maps" showing positive/negative sentiment distribution and time-series charts tracking discussion volume and sentiment over time.

## Citizen Reporting & Feedback Loops
**What it does**: Enables citizens to submit geo-tagged multimedia reports (text, images, video) via web/mobile app, rate alert usefulness, and provide status updates on incidents.

**Why it's important**: Creates participatory governance channels and continuously improves AI model accuracy through human feedback, building trust through transparency.

**How it works**: Citizens report issues through intuitive forms, AI automatically categorizes and plots incidents on the map, and feedback flows back into Vertex AI Pipelines for model retraining. All AI decisions include provenance tracking for accountability.

# User Experience

## User Personas
**City Authority - Emergency Response Coordinator**
- Needs: Real-time situational awareness, predictive alerts, resource allocation insights
- Goals: Reduce response times, prevent incidents from escalating, optimize resource deployment
- Pain Points: Information overload, delayed notifications, fragmented data sources

**City Authority - Urban Planner**
- Needs: Trend analysis, citizen sentiment, long-term pattern recognition
- Goals: Data-driven policy decisions, proactive infrastructure planning, citizen satisfaction
- Pain Points: Lack of predictive insights, difficulty correlating diverse data sources

**Citizen - Daily Commuter**
- Needs: Traffic updates, route optimization, incident notifications for their area
- Goals: Avoid delays, stay informed about neighborhood issues, contribute to city improvement
- Pain Points: Unreliable information, no easy way to report issues, lack of personalized alerts

**Citizen - Neighborhood Resident**
- Needs: Hyperlocal alerts, ability to report civic issues, track resolution status
- Goals: Improve neighborhood quality of life, engage with local governance, stay informed
- Pain Points: Limited civic engagement channels, lack of transparency in issue resolution

## Key User Flows

**Flow 1: Citizen Issue Reporting**
1. User opens mobile app, taps "Report Issue"
2. Selects issue category (traffic, safety, civic infrastructure)
3. Takes photo/video or enters text description
4. App auto-detects location or allows manual placement on map
5. AI processes submission, categorizes, and plots on live dashboard
6. User receives confirmation with tracking ID
7. User gets status updates as authorities address the issue

**Flow 2: Authority Dashboard Monitoring**
1. Authority logs into dashboard, sees real-time city overview
2. Reviews color-coded KPI gauges (green/yellow/red) for city health metrics
3. Clicks on incident cluster to see details and AI-generated summary
4. Reviews predictive alerts and resource deployment recommendations
5. Drills down into specific neighborhoods or issue categories
6. Assigns resources or escalates issues based on AI insights

**Flow 3: Personalized Citizen Alerts**
1. Citizen sets location preferences and alert categories in app
2. AI monitors relevant data streams for user's area of interest
3. When threshold is met, system generates personalized alert
4. Push notification sent with summary and actionable information
5. User can confirm/flag alert accuracy for model improvement
6. User receives follow-up when situation is resolved

## UI/UX Considerations
- **Map-Centric Design**: Primary interface is an interactive map with intuitive zoom and filter controls
- **Multi-Language Support**: Localized interface supporting regional languages
- **Accessibility**: WCAG 2.1 compliant with proper contrast ratios and screen reader support
- **Real-Time Updates**: WebSocket connections ensure live data refresh without page reloads
- **Mobile-First**: Responsive design optimized for mobile reporting and consumption
- **Progressive Disclosure**: Complex data presented in digestible layers with drill-down capabilities
- **Trust Indicators**: Confidence scores, data source attribution, and AI decision explainability

# Technical Architecture

## System Components

**Data Ingestion Layer**
- Google Cloud Pub/Sub: Message queuing for real-time data streams
- Cloud Dataflow: ETL processing for data cleaning, normalization, geotagging
- API connectors for social media (Twitter, Facebook), traffic systems, IoT sensors
- Citizen submission forms with multimedia upload capabilities

**AI/ML Processing Engine**
- Vertex AI Model Garden: 200+ pretrained models for NLP, vision, and forecasting
- Gemini 2.0/2.5: Multimodal LLM for text analysis and narrative generation
- Vision API: Image and video content analysis
- Imagen: Custom visual generation for UI elements
- Vertex AI Agents: RAG-enabled workflows for autonomous processing
- BigQuery ML: In-database machine learning for scalable analytics

**Data Storage & Management**
- BigQuery: Primary analytics database for data fusion and time-series analysis
- Firestore: Real-time user data, current incident status, session management
- Cloud Storage: Multimedia file storage with CDN distribution
- Vertex Feature Store: Feature management for online ML inference

**Backend Services**
- Cloud Functions: Serverless execution for processing tasks
- API Gateway: Request routing and authentication
- Vertex AI Pipelines: ML workflow orchestration
- Cloud Scheduler: Automated batch processing jobs

**Frontend & User Services**
- React/Next.js: Web application framework
- Flutter: Cross-platform mobile application
- Firebase Hosting: Static site hosting with global CDN
- Google Maps JavaScript API: Interactive mapping and geocoding
- Material Design: Consistent UI component library

**Notification & Communication**
- Firebase Cloud Messaging: Push notifications for mobile and web
- Email/SMS integration for critical alerts
- WebSocket connections for real-time dashboard updates

## Data Models

**Event Schema**
```json
{
  "id": "uuid",
  "type": "traffic|safety|civic|weather|social",
  "title": "string",
  "description": "text",
  "location": {
    "lat": "float",
    "lng": "float",
    "address": "string",
    "ward": "string"
  },
  "timestamp": "datetime",
  "media": ["url_array"],
  "source": "social|citizen|official|sensor",
  "severity": "low|medium|high|critical",
  "status": "active|resolved|monitoring",
  "cluster_id": "uuid",
  "confidence_score": "float",
  "tags": ["string_array"],
  "sentiment_score": "float"
}
```

**User Profile Schema**
```json
{
  "user_id": "uuid",
  "role": "citizen|authority|admin",
  "preferences": {
    "alert_categories": ["string_array"],
    "locations": ["location_array"],
    "notification_methods": ["push|email|sms"]
  },
  "subscriptions": ["event_filter_array"],
  "reputation_score": "integer"
}
```

**Feedback Schema**
```json
{
  "feedback_id": "uuid",
  "event_id": "uuid",
  "user_id": "uuid",
  "rating": "useful|not_useful|false_positive",
  "comment": "text",
  "timestamp": "datetime",
  "feedback_type": "accuracy|relevance|resolution"
}
```

## APIs and Integrations

**External APIs**
- Social Media: Twitter API v2, Facebook Graph API, Reddit API
- Government: Municipal 311 systems, traffic management APIs
- Weather: National Weather Service, AccuWeather API
- Transportation: GTFS feeds, ride-sharing APIs
- IoT: City sensor networks, air quality monitors

**Internal APIs**
- Events API: CRUD operations for incident management
- Analytics API: Real-time metrics and trend data
- User API: Profile management and preferences
- Notification API: Alert delivery and subscription management
- Feedback API: User rating and comment collection

**Google Cloud Service Integration**
- Vertex AI: Model training, inference, and agent orchestration
- BigQuery: SQL-based analytics and ML model training
- Vision API: Image and video analysis
- Maps API: Geocoding, routing, and visualization
- Firebase: Authentication, real-time database, cloud messaging

## Infrastructure Requirements

**Compute & Scaling**
- Serverless architecture using Cloud Functions and Cloud Run
- Auto-scaling based on data volume and user load
- Global load balancing for multi-region deployment
- Container orchestration via Google Kubernetes Engine for stateful services

**Storage & Database**
- BigQuery: Multi-terabyte analytics warehouse with automatic scaling
- Firestore: NoSQL database with real-time synchronization
- Cloud Storage: Object storage with lifecycle management
- Redis: In-memory caching for real-time features

**Security & Compliance**
- Identity and Access Management (IAM) with role-based permissions
- VPC with private subnets for sensitive processing
- Data encryption at rest and in transit
- GDPR compliance for EU users, with data residency controls
- Audit logging for all system operations

**Monitoring & Operations**
- Cloud Monitoring: System metrics and alerting
- Cloud Logging: Centralized log aggregation
- Error Reporting: Automated error detection and notification
- Performance monitoring with user experience tracking

# Development Roadmap

## Phase 1: Foundation MVP (Core Infrastructure)
**Goal**: Establish basic data ingestion, storage, and simple visualization

**Scope**:
- Set up Google Cloud infrastructure (BigQuery, Firestore, Pub/Sub)
- Implement basic data ingestion for 2 sources: social media (Twitter) + citizen reports
- Create fundamental data models (Event, User, Feedback schemas)
- Build simple REST API for event CRUD operations
- Develop basic web frontend with map visualization using Google Maps API
- Implement citizen report submission (text + single image)
- Basic event display on map with category filtering
- Simple push notification system via Firebase

**Deliverables**:
- Functional data pipeline ingesting Twitter feeds
- Web app where citizens can submit text/image reports
- Map showing reported incidents with basic details
- Admin panel for viewing all incidents

## Phase 2: AI Processing & Clustering (Intelligence Layer)
**Goal**: Add AI-powered event processing and basic automation

**Scope**:
- Integrate Vertex AI Gemini for text analysis and summarization
- Implement Vision API for image content analysis
- Build event clustering algorithm to group related incidents
- Add basic sentiment analysis for social media content
- Create automated event categorization and severity assessment
- Implement basic AI agent for processing citizen reports
- Add confidence scoring for AI-generated insights
- Build simple trend detection for incident types

**Deliverables**:
- AI automatically categorizes and describes citizen-submitted images
- Related incidents are clustered and summarized
- Social media sentiment appears on dashboard
- Basic AI-generated alerts for incident clusters

## Phase 3: Enhanced Dashboard & User Experience
**Goal**: Create polished, usable interface with real-time updates

**Scope**:
- Develop comprehensive dashboard with multiple visualization layers
- Implement real-time updates via WebSocket connections
- Add heatmaps for incident density and sentiment visualization
- Create KPI gauges for city health metrics
- Build user preference system for personalized alerts
- Implement feedback mechanisms (rating alerts, confirming status)
- Add mobile app using Flutter for iOS/Android
- Enhance map interface with custom markers and layered views

**Deliverables**:
- Professional dashboard with real-time updates
- Mobile apps for citizen reporting and alert consumption
- Personalized alert system based on user preferences
- Interactive heatmaps and trend visualizations

## Phase 4: Predictive Analytics & Advanced AI
**Goal**: Add forecasting, anomaly detection, and sophisticated AI workflows

**Scope**:
- Implement BigQuery ML models for trend forecasting
- Build anomaly detection for unusual incident patterns
- Create RAG-powered agents for complex data analysis
- Add time-series forecasting for resource planning
- Implement advanced correlation detection across data sources
- Build executive reporting with predictive insights
- Add automated resource deployment recommendations
- Create sophisticated alert rules with ML-based filtering

**Deliverables**:
- Predictive alerts for potential incidents (traffic surges, infrastructure failures)
- Automated trend analysis reports
- Resource optimization recommendations
- Advanced AI agents handling complex multi-step analysis

## Phase 5: Scale & Enhancement
**Goal**: Handle city-wide deployment with advanced features

**Scope**:
- Multi-language support and localization
- Integration with additional data sources (IoT sensors, city databases)
- Advanced video analysis capabilities
- Role-based dashboards for different authority types
- Public API for third-party integrations
- Enhanced security and compliance features
- Performance optimization for city-wide scale
- Advanced feedback loops and model retraining

**Deliverables**:
- Production-ready system handling city-wide data volumes
- Multiple language support
- Public API for ecosystem integration
- Advanced security and compliance certifications

# Logical Dependency Chain

## Foundation First (Infrastructure & Basic Data Flow)
**Dependencies**: None
**Components**:
- Cloud infrastructure setup (BigQuery, Firestore, Pub/Sub)
- Basic data ingestion pipeline
- Core data models and schemas
- Simple REST API foundation

**Why First**: All subsequent features depend on having reliable data storage and basic ingestion capabilities. Without this foundation, no other features can function.

## Data Processing Before Intelligence (Raw Data → Structured Data)
**Dependencies**: Foundation infrastructure
**Components**:
- Data cleaning and normalization
- Basic event storage and retrieval
- Simple categorization (manual or rule-based)

**Why Next**: AI features require clean, structured data. Establishing reliable data processing ensures AI models have quality inputs and creates a fallback for when AI fails.

## Minimal Viable Frontend (Early User Validation)
**Dependencies**: Basic data processing
**Components**:
- Simple map interface with event markers
- Basic citizen reporting form
- Event display with filtering

**Why Critical**: Getting a working frontend early allows for user testing and feedback, preventing costly architectural changes later. Users can immediately see value and provide input on core workflows.

## AI Enhancement Layer (Intelligence on Proven Foundation)
**Dependencies**: Working frontend + reliable data flow
**Components**:
- Vertex AI integration for text/image analysis
- Event clustering and summarization
- Basic automated categorization

**Why This Order**: Building AI on top of a proven data foundation reduces risk. If AI features fail, the system still functions with manual/rule-based processing. Users can immediately see AI value-add compared to the basic version.

## Real-Time Features (User Engagement)
**Dependencies**: AI processing working reliably
**Components**:
- WebSocket connections for live updates
- Push notification system
- Real-time dashboard refresh

**Why After AI**: Real-time features are most valuable when they're delivering intelligent, processed information rather than raw data floods. Users need meaningful real-time updates, not just faster raw data.

## Advanced Analytics (Value Multiplication)
**Dependencies**: Substantial data history + proven AI pipeline
**Components**:
- Predictive modeling
- Trend analysis
- Anomaly detection

**Why Last**: Predictive features require historical data to train on and proven AI pipelines to build upon. These features multiply the value of existing capabilities rather than creating new core value.

## Parallel Development Streams
**Stream A (Backend)**: Infrastructure → Data Processing → AI Integration → Analytics
**Stream B (Frontend)**: Basic Map → Enhanced UI → Mobile App → Advanced Visualizations
**Stream C (Integration)**: Core APIs → External Integrations → Advanced Features

This allows frontend and backend development to proceed in parallel once basic data models are established.

# Risks and Mitigations

## Technical Challenges

**Risk**: AI Model Accuracy and Reliability
- *Challenge*: Multimodal AI may misclassify incidents, generate false alerts, or miss critical events
- *Mitigation*: Start with high-confidence scenarios, implement human-in-the-loop validation for critical alerts, provide confidence scores for all AI decisions, build robust feedback loops to continuously improve models
- *MVP Approach*: Begin with simple text analysis and basic image recognition, expand to complex multimodal analysis only after proving foundation capabilities

**Risk**: Real-Time Data Processing at Scale
- *Challenge*: City-wide data streams may overwhelm processing capabilities or create latency issues
- *Mitigation*: Use Google Cloud's managed services (Pub/Sub, Dataflow) designed for scale, implement data sampling and filtering strategies, design graceful degradation when systems are overloaded
- *MVP Approach*: Start with limited geographic area and data sources, gradually expand scope as system proves stable

**Risk**: Data Quality and Integration Complexity
- *Challenge*: Urban data is notoriously messy, inconsistent, and difficult to correlate across sources
- *Mitigation*: Build robust data validation and cleaning pipelines, start with highest-quality data sources, implement data quality monitoring and alerting
- *MVP Approach*: Begin with 2-3 well-structured data sources, add more complex sources incrementally as processing capabilities mature

## MVP Scope and Buildability

**Risk**: Feature Scope Creep Leading to Undeliverable MVP
- *Challenge*: Temptation to build comprehensive system immediately rather than proving core value
- *Mitigation*: Ruthlessly prioritize core user flows (citizen reporting → AI processing → authority dashboard), defer advanced features like predictive analytics to later phases
- *MVP Definition*: Citizens can report issues with photos, AI can categorize and cluster reports, authorities can view incidents on map with basic filtering—nothing more

**Risk**: Over-Engineering Early Architecture
- *Challenge*: Building for city-wide scale before proving product-market fit
- *Mitigation*: Use simple, proven patterns for MVP (REST APIs, basic React frontend, standard database schemas), design for refactoring rather than perfect scalability
- *MVP Approach*: Build for hundreds of users and thousands of events, not millions—optimize for development speed and user validation

**Risk**: AI Complexity Blocking Core Features
- *Challenge*: Spending too much time perfecting AI models while basic user workflows remain broken
- *Mitigation*: Implement "AI-assisted" rather than "AI-automated" features initially, allow manual override for all AI decisions, focus on 80/20 rule for AI accuracy
- *MVP Strategy*: AI suggests categories and clusters, humans confirm—automation comes after proving the human workflow works

## Resource and Execution Constraints

**Risk**: Limited AI/ML Expertise
- *Challenge*: Complex AI features require specialized knowledge that may not be available
- *Mitigation*: Leverage managed AI services (Vertex AI, pre-trained models) rather than building from scratch, start with well-documented use cases, plan for external ML consulting if needed
- *Resource Strategy*: Use Google's pre-built models and focus engineering effort on integration and user experience rather than model development

**Risk**: Government/Authority Adoption Barriers
- *Challenge*: City authorities may be slow to adopt new technology or have complex procurement requirements
- *Mitigation*: Start with citizen-facing features that don't require authority integration, build proof of value before requesting official partnerships, design system to work with public data initially
- *Go-to-Market*: Launch as citizen tool first, demonstrate value to authorities through usage and results

**Risk**: Data Privacy and Security Compliance
- *Challenge*: Urban data involves sensitive citizen information and government operations
- *Mitigation*: Design privacy-first architecture, use only public data or explicit user consent, implement comprehensive audit logging, plan for GDPR/privacy regulation compliance from start
- *Technical Strategy*: Anonymous data aggregation, user consent workflows, comprehensive data retention policies

**Risk**: Funding and Sustainability
- *Challenge*: Smart city projects often require substantial ongoing investment
- *Mitigation*: Design for multiple revenue models (SaaS for authorities, citizen premium features, data insights licensing), build cost-efficient architecture using managed services, plan freemium model for initial adoption
- *Business Strategy*: Start with grant funding or pilot partnerships, prove ROI before requiring significant municipal budgets

# Appendix

## Research Findings

### Global Smart City Case Studies Analysis

**Rome - Real-Time Mobility Intelligence**
- *Approach*: Cell-tower and GPS data fusion for traffic and pedestrian flow analysis
- *Key Learnings*: Anonymous mobile data provides reliable real-time insights when properly aggregated
- *Application to CityPulse*: Integrate traffic and mobility APIs with incident reporting to provide comprehensive transportation intelligence

**Tel Aviv - ZenCity Social Sentiment Platform**
- *Approach*: AI-driven municipal social media analysis for policy decisions
- *Key Learnings*: Social sentiment analysis provides early warning for citizen dissatisfaction and emerging issues
- *Application to CityPulse*: Implement continuous social media monitoring with neighborhood-level sentiment mapping

**Bengaluru Police - Social Content Analytics**
- *Approach*: AI classification of social media for misinformation detection and trend monitoring
- *Key Learnings*: Automated content analysis can identify problematic trends before they escalate
- *Application to CityPulse*: Expand beyond police use cases to general civic issue detection and monitoring

**IBM Intelligent Operations Centers**
- *Approach*: Multi-source data fusion with rule-based event correlation and executive dashboards
- *Key Learnings*: Unified dashboards reduce information overload, but require sophisticated filtering to avoid alert fatigue
- *Application to CityPulse*: Implement ML-based correlation instead of rule-based, with citizen feedback loops for continuous improvement

### Best Practices for Urban Data Fusion

**Data Quality Management**:
- Implement automated data validation at ingestion
- Use confidence scoring for all AI-generated insights
- Build human review workflows for high-impact decisions
- Maintain data lineage for audit and debugging

**User Experience Design**:
- Prioritize mobile-first design for citizen engagement
- Use progressive disclosure for complex data visualization
- Implement role-based interfaces for different user types
- Ensure accessibility compliance for public sector deployment

**AI Model Development**:
- Start with pre-trained models and fine-tune on local data
- Implement explainable AI for government transparency requirements
- Build feedback loops for continuous model improvement
- Use ensemble methods to improve reliability

## Technical Specifications

### Google Cloud Reference Architecture

**Compute Services**:
- Cloud Functions: Event-driven processing, auto-scaling to zero
- Cloud Run: Containerized services with automatic scaling
- Google Kubernetes Engine: Stateful services requiring persistent connections
- Vertex AI: Managed ML training and inference

**Storage Services**:
- BigQuery: Analytics data warehouse with automatic scaling
- Firestore: Real-time NoSQL database for user sessions and current state
- Cloud Storage: Object storage for multimedia files
- Memorystore (Redis): Caching layer for real-time features

**Integration Services**:
- Pub/Sub: Message queuing for real-time data streams
- Dataflow: Stream and batch data processing
- API Gateway: Request routing and authentication
- Cloud Scheduler: Automated batch processing jobs

**AI/ML Services**:
- Vertex AI Model Garden: Pre-trained models for NLP, vision, forecasting
- Gemini API: Multimodal language model for text analysis and generation
- Vision API: Image and video content analysis
- Translation API: Multi-language support

### Example Data Schemas

**BigQuery Event Analytics Table**:
```sql
CREATE TABLE city_intelligence.events (
  event_id STRING NOT NULL,
  event_type STRING NOT NULL,
  title STRING,
  description STRING,
  location_lat FLOAT64,
  location_lng FLOAT64,
  ward_name STRING,
  timestamp TIMESTAMP NOT NULL,
  source_type STRING NOT NULL,
  severity_level STRING,
  status STRING,
  cluster_id STRING,
  confidence_score FLOAT64,
  sentiment_score FLOAT64,
  tags ARRAY<STRING>,
  media_urls ARRAY<STRING>,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP()
) PARTITION BY DATE(timestamp)
CLUSTER BY ward_name, event_type;
```

**Firestore User Preferences Document**:
```javascript
// Collection: users/{userId}
{
  profile: {
    role: "citizen" | "authority" | "admin",
    display_name: string,
    preferred_language: string,
    created_at: timestamp
  },
  preferences: {
    alert_categories: ["traffic", "safety", "civic"],
    notification_methods: ["push", "email"],
    alert_radius_km: number,
    quiet_hours: {
      start: "22:00",
      end: "08:00"
    }
  },
  subscriptions: [
    {
      location: {lat: number, lng: number},
      radius_km: number,
      categories: ["string"],
      active: boolean
    }
  ],
  activity: {
    reports_submitted: number,
    feedback_provided: number,
    last_active: timestamp
  }
}
```

### API Endpoint Specifications

**Events API**:
- `GET /api/v1/events` - List events with filtering and pagination
- `POST /api/v1/events` - Create new event (citizen reporting)
- `GET /api/v1/events/{id}` - Get specific event details
- `PUT /api/v1/events/{id}` - Update event status (authorities only)
- `POST /api/v1/events/{id}/feedback` - Submit user feedback

**Analytics API**:
- `GET /api/v1/analytics/trends` - Get trend analysis for date range
- `GET /api/v1/analytics/sentiment` - Get sentiment data by location
- `GET /api/v1/analytics/predictions` - Get predictive insights
- `GET /api/v1/analytics/kpis` - Get key performance indicators

**Notifications API**:
- `POST /api/v1/notifications/subscribe` - Subscribe to alerts
- `PUT /api/v1/notifications/preferences` - Update notification preferences
- `GET /api/v1/notifications/history` - Get notification history
