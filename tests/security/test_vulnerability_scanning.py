"""
Vulnerability scanning and data protection tests for CityPulse.
Tests for common security vulnerabilities and data protection mechanisms.
"""

import pytest
import requests
import json
import time
import hashlib
import secrets
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
from unittest.mock import Mock, patch
import re
import base64
import logging

logger = logging.getLogger(__name__)


class TestVulnerabilityScanning:
    """Tests for common security vulnerabilities."""
    
    def setup_method(self):
        """Setup for each test method."""
        self.base_url = "http://localhost:8000"
        self.session = requests.Session()
    
    @pytest.mark.security
    def test_information_disclosure_prevention(self):
        """Test prevention of information disclosure vulnerabilities."""
        # Test error message information disclosure
        def safe_error_handler(error: Exception) -> Dict[str, str]:
            # Should not expose internal details in production
            if isinstance(error, ValueError):
                return {"error": "Invalid input provided", "code": "INVALID_INPUT"}
            elif isinstance(error, PermissionError):
                return {"error": "Access denied", "code": "ACCESS_DENIED"}
            else:
                return {"error": "An error occurred", "code": "INTERNAL_ERROR"}
        
        # Test various error types
        test_errors = [
            ValueError("Database connection string: postgresql://user:pass@localhost/db"),
            PermissionError("User john.doe@company.com not authorized for admin panel"),
            Exception("Internal server error: /var/log/app.log not found")
        ]
        
        for error in test_errors:
            response = safe_error_handler(error)
            
            # Should not contain sensitive information
            error_message = response["error"]
            assert "password" not in error_message.lower()
            assert "connection string" not in error_message.lower()
            assert "@" not in error_message  # No email addresses
            assert "/var/" not in error_message  # No file paths
            assert "postgresql://" not in error_message  # No connection strings
    
    @pytest.mark.security
    def test_directory_traversal_protection(self):
        """Test protection against directory traversal attacks."""
        # Simulate file serving endpoint
        def safe_file_server(file_path: str, allowed_directory: str = "/app/public") -> bool:
            import os
            
            # Normalize the path
            normalized_path = os.path.normpath(os.path.join(allowed_directory, file_path))
            
            # Ensure the path is within the allowed directory
            if not normalized_path.startswith(os.path.abspath(allowed_directory)):
                raise PermissionError("Access denied")
            
            # Check if file exists (simulated)
            return True
        
        # Test legitimate file access
        legitimate_files = [
            "images/logo.png",
            "css/styles.css",
            "js/app.js",
            "documents/public_report.pdf"
        ]
        
        for file_path in legitimate_files:
            try:
                result = safe_file_server(file_path)
                assert result is True
            except PermissionError:
                pytest.fail(f"Legitimate file access should not be blocked: {file_path}")
        
        # Test directory traversal attempts
        traversal_attempts = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "....//....//....//etc/shadow",
            "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",
            "..%252f..%252f..%252fetc%252fpasswd",
            "....\\\\....\\\\....\\\\windows\\\\system32\\\\drivers\\\\etc\\\\hosts"
        ]
        
        for attempt in traversal_attempts:
            with pytest.raises(PermissionError):
                safe_file_server(attempt)
    
    @pytest.mark.security
    def test_server_side_request_forgery_protection(self):
        """Test protection against SSRF attacks."""
        def safe_url_fetcher(url: str) -> bool:
            import urllib.parse
            
            # Parse the URL
            parsed = urllib.parse.urlparse(url)
            
            # Block internal/private IP ranges
            blocked_hosts = [
                "localhost", "127.0.0.1", "0.0.0.0",
                "10.", "172.16.", "172.17.", "172.18.", "172.19.",
                "172.20.", "172.21.", "172.22.", "172.23.", "172.24.",
                "172.25.", "172.26.", "172.27.", "172.28.", "172.29.",
                "172.30.", "172.31.", "192.168.",
                "169.254.",  # Link-local
                "::1", "::ffff:127.0.0.1"  # IPv6 localhost
            ]
            
            # Block non-HTTP(S) schemes
            if parsed.scheme not in ["http", "https"]:
                raise ValueError("Only HTTP(S) URLs are allowed")
            
            # Check for blocked hosts
            hostname = parsed.hostname or ""
            for blocked in blocked_hosts:
                if hostname.startswith(blocked) or hostname == blocked.rstrip('.'):
                    raise ValueError("Access to internal resources is not allowed")
            
            # Block common internal services
            if parsed.port in [22, 23, 25, 53, 110, 143, 993, 995, 3306, 5432, 6379, 27017]:
                raise ValueError("Access to internal services is not allowed")
            
            return True
        
        # Test legitimate external URLs
        legitimate_urls = [
            "https://api.example.com/data",
            "http://public-api.service.com/endpoint",
            "https://cdn.example.org/image.jpg"
        ]
        
        for url in legitimate_urls:
            try:
                result = safe_url_fetcher(url)
                assert result is True
            except ValueError:
                pytest.fail(f"Legitimate URL should not be blocked: {url}")
        
        # Test SSRF attempts
        ssrf_attempts = [
            "http://localhost:8080/admin",
            "http://127.0.0.1:22/",
            "http://10.0.0.1/internal",
            "http://172.16.0.1/config",
            "http://192.168.1.1/router",
            "file:///etc/passwd",
            "ftp://internal.server.com/data",
            "gopher://127.0.0.1:6379/_INFO",
            "http://169.254.169.254/latest/meta-data/"  # AWS metadata
        ]
        
        for attempt in ssrf_attempts:
            with pytest.raises(ValueError):
                safe_url_fetcher(attempt)
    
    @pytest.mark.security
    def test_xml_external_entity_protection(self):
        """Test protection against XXE attacks."""
        import xml.etree.ElementTree as ET
        from xml.parsers.expat import ParserCreateNS
        
        def safe_xml_parser(xml_content: str) -> Dict[str, Any]:
            # Disable external entity processing
            parser = ParserCreateNS()
            parser.DefaultHandler = lambda data: None
            parser.ExternalEntityRefHandler = lambda context, base, sysId, notationName: False
            
            try:
                # Parse XML safely
                root = ET.fromstring(xml_content)
                return {"status": "success", "root_tag": root.tag}
            except ET.ParseError as e:
                return {"status": "error", "message": "Invalid XML"}
            except Exception as e:
                return {"status": "error", "message": "XML processing error"}
        
        # Test legitimate XML
        legitimate_xml = """<?xml version="1.0"?>
        <event>
            <title>Test Event</title>
            <description>This is a test event</description>
        </event>"""
        
        result = safe_xml_parser(legitimate_xml)
        assert result["status"] == "success"
        
        # Test XXE attempts
        xxe_attempts = [
            """<?xml version="1.0"?>
            <!DOCTYPE event [
                <!ENTITY xxe SYSTEM "file:///etc/passwd">
            ]>
            <event><title>&xxe;</title></event>""",
            
            """<?xml version="1.0"?>
            <!DOCTYPE event [
                <!ENTITY xxe SYSTEM "http://attacker.com/malicious">
            ]>
            <event><title>&xxe;</title></event>""",
            
            """<?xml version="1.0"?>
            <!DOCTYPE event [
                <!ENTITY % xxe SYSTEM "file:///etc/passwd">
                %xxe;
            ]>
            <event><title>Test</title></event>"""
        ]
        
        for attempt in xxe_attempts:
            result = safe_xml_parser(attempt)
            # Should either fail to parse or not execute external entities
            assert result["status"] == "error" or "passwd" not in str(result)
    
    @pytest.mark.security
    def test_insecure_deserialization_protection(self):
        """Test protection against insecure deserialization."""
        import pickle
        import json
        
        def safe_data_deserializer(data: str, format_type: str) -> Dict[str, Any]:
            if format_type == "json":
                try:
                    # JSON is generally safe for deserialization
                    return json.loads(data)
                except json.JSONDecodeError:
                    raise ValueError("Invalid JSON data")
            
            elif format_type == "pickle":
                # Pickle is dangerous - should be avoided or heavily restricted
                raise ValueError("Pickle deserialization is not allowed for security reasons")
            
            else:
                raise ValueError("Unsupported data format")
        
        # Test safe JSON deserialization
        safe_json = '{"title": "Test Event", "priority": "high"}'
        result = safe_data_deserializer(safe_json, "json")
        assert result["title"] == "Test Event"
        
        # Test pickle rejection
        malicious_pickle = "malicious_pickle_data"
        with pytest.raises(ValueError, match="Pickle deserialization is not allowed"):
            safe_data_deserializer(malicious_pickle, "pickle")
    
    @pytest.mark.security
    def test_weak_cryptography_detection(self):
        """Test detection of weak cryptographic practices."""
        import hashlib
        import secrets
        
        def validate_password_hash(hash_algorithm: str, salt_length: int) -> List[str]:
            issues = []
            
            # Check for weak hash algorithms
            weak_algorithms = ["md5", "sha1"]
            if hash_algorithm.lower() in weak_algorithms:
                issues.append(f"Weak hash algorithm: {hash_algorithm}")
            
            # Check salt length
            if salt_length < 16:
                issues.append(f"Salt too short: {salt_length} bytes (minimum 16)")
            
            return issues
        
        def validate_encryption_key(key_length: int, algorithm: str) -> List[str]:
            issues = []
            
            # Check key length for different algorithms
            min_key_lengths = {
                "aes": 256,
                "rsa": 2048,
                "ecdsa": 256
            }
            
            min_length = min_key_lengths.get(algorithm.lower(), 256)
            if key_length < min_length:
                issues.append(f"Key too short for {algorithm}: {key_length} bits (minimum {min_length})")
            
            return issues
        
        # Test strong cryptography (should pass)
        strong_configs = [
            ("sha256", 32),  # Strong hash with good salt
            ("bcrypt", 16),  # Strong hash with good salt
            ("argon2", 24)   # Strong hash with good salt
        ]
        
        for algorithm, salt_length in strong_configs:
            issues = validate_password_hash(algorithm, salt_length)
            assert len(issues) == 0, f"Strong config should not have issues: {algorithm}"
        
        # Test weak cryptography (should fail)
        weak_configs = [
            ("md5", 8),      # Weak hash, short salt
            ("sha1", 12),    # Weak hash
            ("sha256", 4)    # Strong hash but short salt
        ]
        
        for algorithm, salt_length in weak_configs:
            issues = validate_password_hash(algorithm, salt_length)
            assert len(issues) > 0, f"Weak config should have issues: {algorithm}"
        
        # Test encryption key validation
        strong_keys = [
            (256, "aes"),
            (2048, "rsa"),
            (384, "ecdsa")
        ]
        
        for key_length, algorithm in strong_keys:
            issues = validate_encryption_key(key_length, algorithm)
            assert len(issues) == 0, f"Strong key should not have issues: {algorithm}"
        
        weak_keys = [
            (128, "aes"),    # Too short for AES
            (1024, "rsa"),   # Too short for RSA
            (128, "ecdsa")   # Too short for ECDSA
        ]
        
        for key_length, algorithm in weak_keys:
            issues = validate_encryption_key(key_length, algorithm)
            assert len(issues) > 0, f"Weak key should have issues: {algorithm}"


class TestDataProtection:
    """Tests for data protection and privacy mechanisms."""
    
    @pytest.mark.security
    def test_pii_data_masking(self):
        """Test PII data masking and anonymization."""
        def mask_pii_data(data: Dict[str, Any]) -> Dict[str, Any]:
            masked_data = data.copy()
            
            # Mask email addresses
            if "email" in masked_data:
                email = masked_data["email"]
                if "@" in email:
                    username, domain = email.split("@", 1)
                    masked_username = username[:2] + "*" * (len(username) - 2)
                    masked_data["email"] = f"{masked_username}@{domain}"
            
            # Mask phone numbers
            if "phone" in masked_data:
                phone = masked_data["phone"]
                if len(phone) >= 4:
                    masked_data["phone"] = "*" * (len(phone) - 4) + phone[-4:]
            
            # Mask credit card numbers
            if "credit_card" in masked_data:
                cc = masked_data["credit_card"]
                if len(cc) >= 4:
                    masked_data["credit_card"] = "*" * (len(cc) - 4) + cc[-4:]
            
            # Remove sensitive fields entirely
            sensitive_fields = ["ssn", "password", "api_key", "secret"]
            for field in sensitive_fields:
                if field in masked_data:
                    masked_data[field] = "[REDACTED]"
            
            return masked_data
        
        # Test PII masking
        original_data = {
            "name": "John Doe",
            "email": "john.doe@example.com",
            "phone": "555-123-4567",
            "credit_card": "4111111111111111",
            "ssn": "123-45-6789",
            "password": "secret123",
            "address": "123 Main St"
        }
        
        masked_data = mask_pii_data(original_data)
        
        # Verify masking
        assert masked_data["name"] == "John Doe"  # Name not masked
        assert masked_data["email"] == "jo*@example.com"
        assert masked_data["phone"] == "********4567"
        assert masked_data["credit_card"] == "************1111"
        assert masked_data["ssn"] == "[REDACTED]"
        assert masked_data["password"] == "[REDACTED]"
        assert masked_data["address"] == "123 Main St"  # Address not masked
    
    @pytest.mark.security
    def test_data_encryption_at_rest(self):
        """Test data encryption at rest."""
        from cryptography.fernet import Fernet
        
        def encrypt_sensitive_data(data: str, key: bytes) -> str:
            f = Fernet(key)
            encrypted_data = f.encrypt(data.encode())
            return base64.b64encode(encrypted_data).decode()
        
        def decrypt_sensitive_data(encrypted_data: str, key: bytes) -> str:
            f = Fernet(key)
            decoded_data = base64.b64decode(encrypted_data.encode())
            decrypted_data = f.decrypt(decoded_data)
            return decrypted_data.decode()
        
        # Generate encryption key
        key = Fernet.generate_key()
        
        # Test data encryption/decryption
        sensitive_data = "This is sensitive user information"
        
        # Encrypt data
        encrypted = encrypt_sensitive_data(sensitive_data, key)
        assert encrypted != sensitive_data
        assert len(encrypted) > len(sensitive_data)
        
        # Decrypt data
        decrypted = decrypt_sensitive_data(encrypted, key)
        assert decrypted == sensitive_data
        
        # Test with wrong key (should fail)
        wrong_key = Fernet.generate_key()
        with pytest.raises(Exception):
            decrypt_sensitive_data(encrypted, wrong_key)
    
    @pytest.mark.security
    def test_data_retention_policies(self):
        """Test data retention and deletion policies."""
        def apply_data_retention_policy(records: List[Dict[str, Any]]) -> Dict[str, Any]:
            current_time = datetime.utcnow()
            
            # Retention periods (in days)
            retention_policies = {
                "user_activity": 90,
                "audit_logs": 365,
                "user_data": 2555,  # 7 years
                "temporary_data": 30
            }
            
            results = {
                "retained": [],
                "deleted": [],
                "anonymized": []
            }
            
            for record in records:
                record_type = record.get("type")
                created_date = datetime.fromisoformat(record.get("created_at"))
                age_days = (current_time - created_date).days
                
                retention_period = retention_policies.get(record_type, 365)
                
                if age_days > retention_period:
                    if record_type == "user_data":
                        # Anonymize instead of delete for user data
                        anonymized_record = record.copy()
                        anonymized_record["user_id"] = "ANONYMIZED"
                        anonymized_record["email"] = "ANONYMIZED"
                        results["anonymized"].append(anonymized_record)
                    else:
                        results["deleted"].append(record)
                else:
                    results["retained"].append(record)
            
            return results
        
        # Test data with different ages
        test_records = [
            {
                "id": "1",
                "type": "user_activity",
                "user_id": "user123",
                "created_at": (datetime.utcnow() - timedelta(days=30)).isoformat()
            },
            {
                "id": "2",
                "type": "user_activity",
                "user_id": "user456",
                "created_at": (datetime.utcnow() - timedelta(days=120)).isoformat()
            },
            {
                "id": "3",
                "type": "user_data",
                "user_id": "user789",
                "email": "user@example.com",
                "created_at": (datetime.utcnow() - timedelta(days=3000)).isoformat()
            },
            {
                "id": "4",
                "type": "temporary_data",
                "data": "temp_info",
                "created_at": (datetime.utcnow() - timedelta(days=45)).isoformat()
            }
        ]
        
        results = apply_data_retention_policy(test_records)
        
        # Verify retention policy application
        assert len(results["retained"]) == 1  # Only recent user_activity
        assert len(results["deleted"]) == 1   # Old temporary_data
        assert len(results["anonymized"]) == 1  # Old user_data
        
        # Verify anonymization
        anonymized_record = results["anonymized"][0]
        assert anonymized_record["user_id"] == "ANONYMIZED"
        assert anonymized_record["email"] == "ANONYMIZED"
    
    @pytest.mark.security
    def test_gdpr_compliance_features(self):
        """Test GDPR compliance features."""
        def handle_gdpr_request(request_type: str, user_id: str, user_data: Dict[str, Any]) -> Dict[str, Any]:
            if request_type == "access":
                # Right to access - return all user data
                return {
                    "status": "success",
                    "data": user_data,
                    "message": "User data retrieved successfully"
                }
            
            elif request_type == "portability":
                # Right to data portability - return data in structured format
                portable_data = {
                    "user_profile": user_data,
                    "export_date": datetime.utcnow().isoformat(),
                    "format": "JSON"
                }
                return {
                    "status": "success",
                    "data": portable_data,
                    "message": "Data export prepared"
                }
            
            elif request_type == "rectification":
                # Right to rectification - allow data correction
                return {
                    "status": "success",
                    "message": "Data correction request processed"
                }
            
            elif request_type == "erasure":
                # Right to erasure (right to be forgotten)
                return {
                    "status": "success",
                    "message": "User data deletion request processed",
                    "deleted_data_types": ["profile", "activity", "preferences"]
                }
            
            elif request_type == "restriction":
                # Right to restriction of processing
                return {
                    "status": "success",
                    "message": "Data processing restriction applied"
                }
            
            else:
                return {
                    "status": "error",
                    "message": "Invalid request type"
                }
        
        # Test user data
        user_data = {
            "user_id": "user123",
            "email": "user@example.com",
            "name": "John Doe",
            "preferences": {"notifications": True},
            "created_at": "2023-01-01T00:00:00Z"
        }
        
        # Test GDPR rights
        gdpr_requests = [
            "access",
            "portability", 
            "rectification",
            "erasure",
            "restriction"
        ]
        
        for request_type in gdpr_requests:
            result = handle_gdpr_request(request_type, "user123", user_data)
            assert result["status"] == "success"
            
            if request_type == "access":
                assert result["data"] == user_data
            elif request_type == "portability":
                assert "export_date" in result["data"]
                assert result["data"]["format"] == "JSON"
            elif request_type == "erasure":
                assert "deleted_data_types" in result
        
        # Test invalid request
        invalid_result = handle_gdpr_request("invalid", "user123", user_data)
        assert invalid_result["status"] == "error"
    
    @pytest.mark.security
    def test_audit_logging(self):
        """Test security audit logging."""
        def create_audit_log(event_type: str, user_id: str, resource: str, action: str, 
                           ip_address: str, user_agent: str, success: bool) -> Dict[str, Any]:
            audit_entry = {
                "timestamp": datetime.utcnow().isoformat(),
                "event_type": event_type,
                "user_id": user_id,
                "resource": resource,
                "action": action,
                "ip_address": ip_address,
                "user_agent": user_agent,
                "success": success,
                "session_id": secrets.token_hex(16)
            }
            
            # Add risk score based on various factors
            risk_score = 0
            
            # Check for suspicious IP patterns
            if ip_address.startswith("10.") or ip_address.startswith("192.168."):
                risk_score += 1  # Internal IP
            
            # Check for suspicious user agents
            suspicious_agents = ["curl", "wget", "python", "bot"]
            if any(agent in user_agent.lower() for agent in suspicious_agents):
                risk_score += 2
            
            # Check for failed actions
            if not success:
                risk_score += 3
            
            # Check for sensitive actions
            sensitive_actions = ["delete", "admin", "export", "modify_permissions"]
            if any(action_type in action.lower() for action_type in sensitive_actions):
                risk_score += 2
            
            audit_entry["risk_score"] = risk_score
            
            return audit_entry
        
        # Test various audit scenarios
        audit_scenarios = [
            {
                "event_type": "authentication",
                "user_id": "user123",
                "resource": "login",
                "action": "login_attempt",
                "ip_address": "203.0.113.1",
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "success": True
            },
            {
                "event_type": "data_access",
                "user_id": "admin456",
                "resource": "user_data",
                "action": "export_user_data",
                "ip_address": "198.51.100.1",
                "user_agent": "curl/7.68.0",
                "success": True
            },
            {
                "event_type": "authentication",
                "user_id": "unknown",
                "resource": "login",
                "action": "login_attempt",
                "ip_address": "192.168.1.100",
                "user_agent": "python-requests/2.25.1",
                "success": False
            }
        ]
        
        for scenario in audit_scenarios:
            audit_log = create_audit_log(**scenario)
            
            # Verify audit log structure
            assert "timestamp" in audit_log
            assert "risk_score" in audit_log
            assert "session_id" in audit_log
            assert audit_log["event_type"] == scenario["event_type"]
            assert audit_log["success"] == scenario["success"]
            
            # Verify risk scoring
            if not scenario["success"]:
                assert audit_log["risk_score"] >= 3  # Failed actions should have higher risk
            
            if "curl" in scenario["user_agent"] or "python" in scenario["user_agent"]:
                assert audit_log["risk_score"] >= 2  # Suspicious user agents
            
            logger.info(f"Audit log created: {audit_log['event_type']} - Risk Score: {audit_log['risk_score']}")


# Security test utilities
@pytest.fixture
def security_test_config():
    """Security test configuration."""
    return {
        "password_policy": {
            "min_length": 12,
            "require_uppercase": True,
            "require_lowercase": True,
            "require_numbers": True,
            "require_special_chars": True,
            "max_age_days": 90
        },
        "session_config": {
            "timeout_minutes": 30,
            "secure_cookies": True,
            "httponly_cookies": True,
            "samesite": "strict"
        },
        "rate_limiting": {
            "login_attempts": 5,
            "api_requests_per_minute": 100,
            "password_reset_per_hour": 3
        }
    }
