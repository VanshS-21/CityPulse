{
  "environment": "test",
  "start_time": "2025-07-13T10:23:59.651642",
  "end_time": "2025-07-13T10:24:01.784059",
  "duration": 2.1324141025543213,
  "suites": {
    "api_tests": {
      "name": "API Integration Tests",
      "status": "failed",
      "tests": [
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_create_event_success",
          "lineno": 60,
          "outcome": "passed",
          "keywords": [
            "test_create_event_success",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.021807437999996182,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003050039999834553,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0002526019998185802,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_create_event_validation_error",
          "lineno": 69,
          "outcome": "passed",
          "keywords": [
            "test_create_event_validation_error",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00029357000016716484,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00024233399994955107,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00022008100017956167,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_get_events_pagination",
          "lineno": 78,
          "outcome": "passed",
          "keywords": [
            "test_get_events_pagination",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00028562199986481573,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00018200499994236452,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00018330500006413786,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIIntegration::test_complete_event_lifecycle",
          "lineno": 91,
          "outcome": "failed",
          "keywords": [
            "test_complete_event_lifecycle",
            "asyncio",
            "pytestmark",
            "TestEventsAPIIntegration",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002493409999715368,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002493509998657828,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 114,
              "message": "Failed: Complete event lifecycle test failed: 'APITestBase' object has no attribute 'create_test_event'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 114,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIIntegration object at 0x7f1e54dae3d0>\n\n    @pytest.mark.asyncio\n    async def test_complete_event_lifecycle(self):\n        \"\"\"Test complete event lifecycle from creation to cleanup.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            # Authenticate as citizen\n            await test.authenticate_user(\"citizen\")\n    \n            # Create test event\n            event_data = test.test_data[\"events\"][\"validEvent\"]\n>           created_event = await test.create_test_event(event_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'create_test_event'\n\nfeatures/events-management/test_events_api.py:104: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIIntegration object at 0x7f1e54dae3d0>\n\n    @pytest.mark.asyncio\n    async def test_complete_event_lifecycle(self):\n        \"\"\"Test complete event lifecycle from creation to cleanup.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            # Authenticate as citizen\n            await test.authenticate_user(\"citizen\")\n    \n            # Create test event\n            event_data = test.test_data[\"events\"][\"validEvent\"]\n            created_event = await test.create_test_event(event_data)\n    \n            assert \"id\" in created_event\n            assert created_event[\"title\"] == event_data[\"title\"]\n            assert created_event[\"category\"] == event_data[\"category\"]\n    \n            # Cleanup\n            await test.cleanup_test_event(created_event[\"id\"])\n    \n        except Exception as e:\n>           pytest.fail(f\"Complete event lifecycle test failed: {str(e)}\")\nE           Failed: Complete event lifecycle test failed: 'APITestBase' object has no attribute 'create_test_event'\n\nfeatures/events-management/test_events_api.py:114: Failed"
          },
          "teardown": {
            "duration": 0.00029108099988661706,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIIntegration::test_event_authentication_flows",
          "lineno": 117,
          "outcome": "passed",
          "keywords": [
            "test_event_authentication_flows",
            "asyncio",
            "pytestmark",
            "TestEventsAPIIntegration",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002778309999484918,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002441950000502402,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00028091299986954255,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIPerformance::test_api_response_times",
          "lineno": 152,
          "outcome": "failed",
          "keywords": [
            "test_api_response_times",
            "asyncio",
            "pytestmark",
            "TestEventsAPIPerformance",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002751800000169169,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00019852400009767734,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 174,
              "message": "Failed: Performance test failed: 'APITestBase' object has no attribute 'generate_performance_report'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 174,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIPerformance object at 0x7f1e54daf7d0>\n\n    @pytest.mark.asyncio\n    async def test_api_response_times(self):\n        \"\"\"Test API response times are within acceptable limits.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test GET /events response time\n            response = await test.make_request(\"GET\", \"/events\")\n    \n            # Check performance metrics\n>           metrics = test.generate_performance_report()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'generate_performance_report'\n\nfeatures/events-management/test_events_api.py:166: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIPerformance object at 0x7f1e54daf7d0>\n\n    @pytest.mark.asyncio\n    async def test_api_response_times(self):\n        \"\"\"Test API response times are within acceptable limits.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test GET /events response time\n            response = await test.make_request(\"GET\", \"/events\")\n    \n            # Check performance metrics\n            metrics = test.generate_performance_report()\n    \n            if metrics.get(\"average_response_time\", 0) > 2.0:  # 2 second threshold\n                pytest.fail(f\"API response time too slow: {metrics['average_response_time']}s\")\n    \n            assert response.status_code == 200\n    \n        except Exception as e:\n>           pytest.fail(f\"Performance test failed: {str(e)}\")\nE           Failed: Performance test failed: 'APITestBase' object has no attribute 'generate_performance_report'\n\nfeatures/events-management/test_events_api.py:174: Failed"
          },
          "teardown": {
            "duration": 0.00022862800005896133,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIErrorHandling::test_invalid_event_id",
          "lineno": 181,
          "outcome": "failed",
          "keywords": [
            "test_invalid_event_id",
            "asyncio",
            "pytestmark",
            "TestEventsAPIErrorHandling",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00028503800012913416,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002057980000245152,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 199,
              "message": "Failed: Error handling test failed: 'APITestBase' object has no attribute 'validate_error_response'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 199,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIErrorHandling object at 0x7f1e54db8290>\n\n    @pytest.mark.asyncio\n    async def test_invalid_event_id(self):\n        \"\"\"Test handling of invalid event IDs.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with invalid event ID\n            response = await test.make_request(\"GET\", \"/events/invalid-id\")\n            assert response.status_code == 404\n    \n            # Validate error response structure\n>           assert test.validate_error_response(response, 404, [\"error\", \"message\"])\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'validate_error_response'\n\nfeatures/events-management/test_events_api.py:196: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIErrorHandling object at 0x7f1e54db8290>\n\n    @pytest.mark.asyncio\n    async def test_invalid_event_id(self):\n        \"\"\"Test handling of invalid event IDs.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with invalid event ID\n            response = await test.make_request(\"GET\", \"/events/invalid-id\")\n            assert response.status_code == 404\n    \n            # Validate error response structure\n            assert test.validate_error_response(response, 404, [\"error\", \"message\"])\n    \n        except Exception as e:\n>           pytest.fail(f\"Error handling test failed: {str(e)}\")\nE           Failed: Error handling test failed: 'APITestBase' object has no attribute 'validate_error_response'\n\nfeatures/events-management/test_events_api.py:199: Failed"
          },
          "teardown": {
            "duration": 0.00020275099996069912,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIErrorHandling::test_malformed_request_data",
          "lineno": 202,
          "outcome": "failed",
          "keywords": [
            "test_malformed_request_data",
            "asyncio",
            "pytestmark",
            "TestEventsAPIErrorHandling",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00027431600005911605,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00035752600001615065,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 220,
              "message": "Failed: Malformed data test failed: assert 200 == 400\n +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7f1e54cca890>.status_code"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 220,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIErrorHandling object at 0x7f1e54daf590>\n\n    @pytest.mark.asyncio\n    async def test_malformed_request_data(self):\n        \"\"\"Test handling of malformed request data.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with malformed JSON\n            malformed_data = {\"title\": \"\", \"invalid_field\": \"test\"}\n            response = await test.make_request(\"POST\", \"/events\", data=malformed_data)\n    \n>           assert response.status_code == 400\nE           assert 200 == 400\nE            +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7f1e54cca890>.status_code\n\nfeatures/events-management/test_events_api.py:216: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIErrorHandling object at 0x7f1e54daf590>\n\n    @pytest.mark.asyncio\n    async def test_malformed_request_data(self):\n        \"\"\"Test handling of malformed request data.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with malformed JSON\n            malformed_data = {\"title\": \"\", \"invalid_field\": \"test\"}\n            response = await test.make_request(\"POST\", \"/events\", data=malformed_data)\n    \n            assert response.status_code == 400\n            assert test.validate_error_response(response, 400)\n    \n        except Exception as e:\n>           pytest.fail(f\"Malformed data test failed: {str(e)}\")\nE           Failed: Malformed data test failed: assert 200 == 400\nE            +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7f1e54cca890>.status_code\n\nfeatures/events-management/test_events_api.py:220: Failed"
          },
          "teardown": {
            "duration": 0.00021434499990391487,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPISmoke::test_events_endpoint_accessible",
          "lineno": 254,
          "outcome": "passed",
          "keywords": [
            "test_events_endpoint_accessible",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestEventsAPISmoke",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002341240001442202,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00021770100011053728,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00026928800002679054,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPISmoke::test_authentication_works",
          "lineno": 271,
          "outcome": "passed",
          "keywords": [
            "test_authentication_works",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestEventsAPISmoke",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002502259999346279,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0001567330000398215,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00026191599999947357,
            "outcome": "passed"
          }
        }
      ],
      "summary": {
        "passed": 6,
        "failed": 4,
        "total": 10,
        "collected": 20,
        "deselected": 10
      },
      "duration": 0.09667587280273438
    },
    "pipeline_tests": {
      "name": "Data Pipeline Tests",
      "status": "failed",
      "tests": [
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestDataPipelineBasic::test_pipeline_setup",
          "lineno": 79,
          "outcome": "passed",
          "keywords": [
            "test_pipeline_setup",
            "asyncio",
            "pytestmark",
            "TestDataPipelineBasic",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0217653770000652,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003266319999966072,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00028261600004952925,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestDataPipelineBasic::test_test_resource_creation",
          "lineno": 97,
          "outcome": "passed",
          "keywords": [
            "test_test_resource_creation",
            "asyncio",
            "pytestmark",
            "TestDataPipelineBasic",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003243039998324093,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003172330000325019,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00023832599981687963,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPubSubIntegration::test_message_publishing",
          "lineno": 124,
          "outcome": "passed",
          "keywords": [
            "test_message_publishing",
            "asyncio",
            "pytestmark",
            "TestPubSubIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003051579999464593,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00020795199998246972,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00018541700001151185,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPubSubIntegration::test_bulk_message_publishing",
          "lineno": 151,
          "outcome": "failed",
          "keywords": [
            "test_bulk_message_publishing",
            "asyncio",
            "pytestmark",
            "TestPubSubIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00026391500000499946,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00024626899994473206,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 182,
              "message": "Failed: Bulk message publishing test failed: 'trafficEvent'"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 182,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestPubSubIntegration object at 0x7f915d473510>\n\n    @pytest.mark.asyncio\n    async def test_bulk_message_publishing(self):\n        \"\"\"Test publishing multiple messages to Pub/Sub.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic\n            topic_path = await test.create_test_topic()\n    \n            # Publish multiple test messages\n            test_events = [\n                test.test_data[\"events\"][\"validEvent\"],\n>               test.test_data[\"events\"][\"trafficEvent\"],\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n                test.test_data[\"events\"][\"environmentalEvent\"]\n            ]\nE           KeyError: 'trafficEvent'\n\nfeatures/data-pipeline/test_pipeline_e2e.py:166: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestPubSubIntegration object at 0x7f915d473510>\n\n    @pytest.mark.asyncio\n    async def test_bulk_message_publishing(self):\n        \"\"\"Test publishing multiple messages to Pub/Sub.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic\n            topic_path = await test.create_test_topic()\n    \n            # Publish multiple test messages\n            test_events = [\n                test.test_data[\"events\"][\"validEvent\"],\n                test.test_data[\"events\"][\"trafficEvent\"],\n                test.test_data[\"events\"][\"environmentalEvent\"]\n            ]\n    \n            message_ids = []\n            for event in test_events:\n                message_id = await test.publish_test_message(topic_path, event)\n                message_ids.append(message_id)\n    \n            assert len(message_ids) == 3\n            assert len(test.test_messages) == 3\n    \n            # Verify all messages have unique IDs\n            assert len(set(message_ids)) == 3\n    \n        except Exception as e:\n>           pytest.fail(f\"Bulk message publishing test failed: {str(e)}\")\nE           Failed: Bulk message publishing test failed: 'trafficEvent'\n\nfeatures/data-pipeline/test_pipeline_e2e.py:182: Failed"
          },
          "teardown": {
            "duration": 0.0002604710000468913,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestBigQueryIntegration::test_bigquery_data_validation",
          "lineno": 189,
          "outcome": "failed",
          "keywords": [
            "test_bigquery_data_validation",
            "asyncio",
            "pytestmark",
            "TestBigQueryIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00035497099997883197,
            "outcome": "passed"
          },
          "call": {
            "duration": 1.0018554000000677,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 222,
              "message": "Failed: BigQuery validation test failed: assert False is True"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 222,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestBigQueryIntegration object at 0x7f915d480150>\n\n    @pytest.mark.asyncio\n    async def test_bigquery_data_validation(self):\n        \"\"\"Test BigQuery data validation functionality.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic and publish message\n            topic_path = await test.create_test_topic()\n            test_message = test.test_data[\"events\"][\"validEvent\"]\n            await test.publish_test_message(topic_path, test_message)\n    \n            # Test data validation (with mock data since we don't have real pipeline)\n            expected_records = [test_message]\n    \n            # This would normally wait for pipeline processing\n            # For now, we'll test the validation logic itself\n            try:\n                # This will timeout since no real pipeline is running\n                # But it tests the validation framework\n                result = await asyncio.wait_for(\n                    test.validate_bigquery_data(\"events\", expected_records),\n                    timeout=5.0\n                )\n                # If we get here, validation worked (unlikely without real pipeline)\n>               assert result is True\nE               assert False is True\n\nfeatures/data-pipeline/test_pipeline_e2e.py:216: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestBigQueryIntegration object at 0x7f915d480150>\n\n    @pytest.mark.asyncio\n    async def test_bigquery_data_validation(self):\n        \"\"\"Test BigQuery data validation functionality.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic and publish message\n            topic_path = await test.create_test_topic()\n            test_message = test.test_data[\"events\"][\"validEvent\"]\n            await test.publish_test_message(topic_path, test_message)\n    \n            # Test data validation (with mock data since we don't have real pipeline)\n            expected_records = [test_message]\n    \n            # This would normally wait for pipeline processing\n            # For now, we'll test the validation logic itself\n            try:\n                # This will timeout since no real pipeline is running\n                # But it tests the validation framework\n                result = await asyncio.wait_for(\n                    test.validate_bigquery_data(\"events\", expected_records),\n                    timeout=5.0\n                )\n                # If we get here, validation worked (unlikely without real pipeline)\n                assert result is True\n            except asyncio.TimeoutError:\n                # Expected - no real pipeline running\n                pass\n    \n        except Exception as e:\n>           pytest.fail(f\"BigQuery validation test failed: {str(e)}\")\nE           Failed: BigQuery validation test failed: assert False is True\n\nfeatures/data-pipeline/test_pipeline_e2e.py:222: Failed"
          },
          "teardown": {
            "duration": 0.00044604100003198255,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineE2EFlow::test_complete_pipeline_flow",
          "lineno": 229,
          "outcome": "passed",
          "keywords": [
            "test_complete_pipeline_flow",
            "slow",
            "asyncio",
            "pytestmark",
            "TestPipelineE2EFlow",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003855380000459263,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002623889999995299,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00021801299999424373,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineErrorHandling::test_invalid_message_handling",
          "lineno": 251,
          "outcome": "passed",
          "keywords": [
            "test_invalid_message_handling",
            "asyncio",
            "pytestmark",
            "TestPipelineErrorHandling",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00030253600016294513,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00016771899981904426,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00017423899998902925,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineErrorHandling::test_resource_cleanup",
          "lineno": 274,
          "outcome": "passed",
          "keywords": [
            "test_resource_cleanup",
            "asyncio",
            "pytestmark",
            "TestPipelineErrorHandling",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00026856700014832313,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00016699200000402925,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00019093100013378717,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineSmoke::test_gcp_clients_initialization",
          "lineno": 303,
          "outcome": "passed",
          "keywords": [
            "test_gcp_clients_initialization",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestPipelineSmoke",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00023240499990606622,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00019609699984357576,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00021617799984596786,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineSmoke::test_configuration_loading",
          "lineno": 325,
          "outcome": "failed",
          "keywords": [
            "test_configuration_loading",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestPipelineSmoke",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00021651199995176285,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002677120000953437,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 343,
              "message": "Failed: Configuration loading smoke test failed: assert 'database' in {'gcp': {'projectId': 'test-project'}}\n +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7f915d37ad10>.config"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 343,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestPipelineSmoke object at 0x7f915d482510>\n\n    @pytest.mark.smoke\n    @pytest.mark.asyncio\n    async def test_configuration_loading(self):\n        \"\"\"Smoke test: Configuration can be loaded.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            # Test configuration loading\n            assert test.config is not None\n            assert \"gcp\" in test.config\n>           assert \"database\" in test.config\nE           AssertionError: assert 'database' in {'gcp': {'projectId': 'test-project'}}\nE            +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7f915d37ad10>.config\n\nfeatures/data-pipeline/test_pipeline_e2e.py:336: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestPipelineSmoke object at 0x7f915d482510>\n\n    @pytest.mark.smoke\n    @pytest.mark.asyncio\n    async def test_configuration_loading(self):\n        \"\"\"Smoke test: Configuration can be loaded.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            # Test configuration loading\n            assert test.config is not None\n            assert \"gcp\" in test.config\n            assert \"database\" in test.config\n    \n            # Test data loading\n            assert test.test_data is not None\n            assert \"events\" in test.test_data\n    \n        except Exception as e:\n>           pytest.fail(f\"Configuration loading smoke test failed: {str(e)}\")\nE           Failed: Configuration loading smoke test failed: assert 'database' in {'gcp': {'projectId': 'test-project'}}\nE            +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7f915d37ad10>.config\n\nfeatures/data-pipeline/test_pipeline_e2e.py:343: Failed"
          },
          "teardown": {
            "duration": 0.00037567100002888765,
            "outcome": "passed"
          }
        }
      ],
      "summary": {
        "passed": 7,
        "failed": 3,
        "total": 10,
        "collected": 20,
        "deselected": 10
      },
      "duration": 1.0976393222808838
    }
  },
  "summary": {
    "total_tests": 20,
    "passed": 13,
    "failed": 7,
    "skipped": 0,
    "errors": 0
  },
  "performance_metrics": {},
  "coverage_report": {}
}
