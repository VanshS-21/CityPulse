{
  "environment": "test",
  "start_time": "2025-07-13T12:17:38.843232",
  "end_time": "2025-07-13T12:17:41.909323",
  "duration": 3.066089630126953,
  "suites": {
    "api_tests": {
      "name": "API Integration Tests",
      "status": "failed",
      "tests": [
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_create_event_success",
          "lineno": 60,
          "outcome": "passed",
          "keywords": [
            "test_create_event_success",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.020799257999897236,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00025750099985089037,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00029999599973962177,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_create_event_validation_error",
          "lineno": 69,
          "outcome": "passed",
          "keywords": [
            "test_create_event_validation_error",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002879960002246662,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00022899200030224165,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0001902119997794216,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_get_events_pagination",
          "lineno": 78,
          "outcome": "passed",
          "keywords": [
            "test_get_events_pagination",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002807209998536564,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00021792400002595969,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00016915500009417883,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIIntegration::test_complete_event_lifecycle",
          "lineno": 91,
          "outcome": "failed",
          "keywords": [
            "test_complete_event_lifecycle",
            "asyncio",
            "pytestmark",
            "TestEventsAPIIntegration",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002990509997289337,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00019831899999189773,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 114,
              "message": "Failed: Complete event lifecycle test failed: 'APITestBase' object has no attribute 'create_test_event'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 114,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIIntegration object at 0x7ff5d980b3d0>\n\n    @pytest.mark.asyncio\n    async def test_complete_event_lifecycle(self):\n        \"\"\"Test complete event lifecycle from creation to cleanup.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            # Authenticate as citizen\n            await test.authenticate_user(\"citizen\")\n    \n            # Create test event\n            event_data = test.test_data[\"events\"][\"validEvent\"]\n>           created_event = await test.create_test_event(event_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'create_test_event'\n\nfeatures/events-management/test_events_api.py:104: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIIntegration object at 0x7ff5d980b3d0>\n\n    @pytest.mark.asyncio\n    async def test_complete_event_lifecycle(self):\n        \"\"\"Test complete event lifecycle from creation to cleanup.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            # Authenticate as citizen\n            await test.authenticate_user(\"citizen\")\n    \n            # Create test event\n            event_data = test.test_data[\"events\"][\"validEvent\"]\n            created_event = await test.create_test_event(event_data)\n    \n            assert \"id\" in created_event\n            assert created_event[\"title\"] == event_data[\"title\"]\n            assert created_event[\"category\"] == event_data[\"category\"]\n    \n            # Cleanup\n            await test.cleanup_test_event(created_event[\"id\"])\n    \n        except Exception as e:\n>           pytest.fail(f\"Complete event lifecycle test failed: {str(e)}\")\nE           Failed: Complete event lifecycle test failed: 'APITestBase' object has no attribute 'create_test_event'\n\nfeatures/events-management/test_events_api.py:114: Failed"
          },
          "teardown": {
            "duration": 0.00020520799989753868,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIIntegration::test_event_authentication_flows",
          "lineno": 117,
          "outcome": "passed",
          "keywords": [
            "test_event_authentication_flows",
            "asyncio",
            "pytestmark",
            "TestEventsAPIIntegration",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002704700000322191,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00019514199993864167,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0002565790000517154,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIPerformance::test_api_response_times",
          "lineno": 152,
          "outcome": "failed",
          "keywords": [
            "test_api_response_times",
            "asyncio",
            "pytestmark",
            "TestEventsAPIPerformance",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00022403699995265924,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00019062199999098084,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 174,
              "message": "Failed: Performance test failed: 'APITestBase' object has no attribute 'generate_performance_report'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 174,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIPerformance object at 0x7ff5d98147d0>\n\n    @pytest.mark.asyncio\n    async def test_api_response_times(self):\n        \"\"\"Test API response times are within acceptable limits.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test GET /events response time\n            response = await test.make_request(\"GET\", \"/events\")\n    \n            # Check performance metrics\n>           metrics = test.generate_performance_report()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'generate_performance_report'\n\nfeatures/events-management/test_events_api.py:166: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIPerformance object at 0x7ff5d98147d0>\n\n    @pytest.mark.asyncio\n    async def test_api_response_times(self):\n        \"\"\"Test API response times are within acceptable limits.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test GET /events response time\n            response = await test.make_request(\"GET\", \"/events\")\n    \n            # Check performance metrics\n            metrics = test.generate_performance_report()\n    \n            if metrics.get(\"average_response_time\", 0) > 2.0:  # 2 second threshold\n                pytest.fail(f\"API response time too slow: {metrics['average_response_time']}s\")\n    \n            assert response.status_code == 200\n    \n        except Exception as e:\n>           pytest.fail(f\"Performance test failed: {str(e)}\")\nE           Failed: Performance test failed: 'APITestBase' object has no attribute 'generate_performance_report'\n\nfeatures/events-management/test_events_api.py:174: Failed"
          },
          "teardown": {
            "duration": 0.00019210700020266813,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIErrorHandling::test_invalid_event_id",
          "lineno": 181,
          "outcome": "failed",
          "keywords": [
            "test_invalid_event_id",
            "asyncio",
            "pytestmark",
            "TestEventsAPIErrorHandling",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003372230003151344,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00019974299993918976,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 199,
              "message": "Failed: Error handling test failed: 'APITestBase' object has no attribute 'validate_error_response'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 199,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIErrorHandling object at 0x7ff5d9815290>\n\n    @pytest.mark.asyncio\n    async def test_invalid_event_id(self):\n        \"\"\"Test handling of invalid event IDs.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with invalid event ID\n            response = await test.make_request(\"GET\", \"/events/invalid-id\")\n            assert response.status_code == 404\n    \n            # Validate error response structure\n>           assert test.validate_error_response(response, 404, [\"error\", \"message\"])\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'validate_error_response'\n\nfeatures/events-management/test_events_api.py:196: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIErrorHandling object at 0x7ff5d9815290>\n\n    @pytest.mark.asyncio\n    async def test_invalid_event_id(self):\n        \"\"\"Test handling of invalid event IDs.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with invalid event ID\n            response = await test.make_request(\"GET\", \"/events/invalid-id\")\n            assert response.status_code == 404\n    \n            # Validate error response structure\n            assert test.validate_error_response(response, 404, [\"error\", \"message\"])\n    \n        except Exception as e:\n>           pytest.fail(f\"Error handling test failed: {str(e)}\")\nE           Failed: Error handling test failed: 'APITestBase' object has no attribute 'validate_error_response'\n\nfeatures/events-management/test_events_api.py:199: Failed"
          },
          "teardown": {
            "duration": 0.00018705900038185064,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIErrorHandling::test_malformed_request_data",
          "lineno": 202,
          "outcome": "failed",
          "keywords": [
            "test_malformed_request_data",
            "asyncio",
            "pytestmark",
            "TestEventsAPIErrorHandling",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00023593100013385992,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003363829996487766,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 220,
              "message": "Failed: Malformed data test failed: assert 200 == 400\n +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7ff5d9722810>.status_code"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 220,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIErrorHandling object at 0x7ff5d9815a90>\n\n    @pytest.mark.asyncio\n    async def test_malformed_request_data(self):\n        \"\"\"Test handling of malformed request data.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with malformed JSON\n            malformed_data = {\"title\": \"\", \"invalid_field\": \"test\"}\n            response = await test.make_request(\"POST\", \"/events\", data=malformed_data)\n    \n>           assert response.status_code == 400\nE           assert 200 == 400\nE            +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7ff5d9722810>.status_code\n\nfeatures/events-management/test_events_api.py:216: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIErrorHandling object at 0x7ff5d9815a90>\n\n    @pytest.mark.asyncio\n    async def test_malformed_request_data(self):\n        \"\"\"Test handling of malformed request data.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with malformed JSON\n            malformed_data = {\"title\": \"\", \"invalid_field\": \"test\"}\n            response = await test.make_request(\"POST\", \"/events\", data=malformed_data)\n    \n            assert response.status_code == 400\n            assert test.validate_error_response(response, 400)\n    \n        except Exception as e:\n>           pytest.fail(f\"Malformed data test failed: {str(e)}\")\nE           Failed: Malformed data test failed: assert 200 == 400\nE            +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7ff5d9722810>.status_code\n\nfeatures/events-management/test_events_api.py:220: Failed"
          },
          "teardown": {
            "duration": 0.00020203000030960538,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPISmoke::test_events_endpoint_accessible",
          "lineno": 254,
          "outcome": "passed",
          "keywords": [
            "test_events_endpoint_accessible",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestEventsAPISmoke",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00022419900005843374,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003017190001628478,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00015285899962691474,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPISmoke::test_authentication_works",
          "lineno": 271,
          "outcome": "passed",
          "keywords": [
            "test_authentication_works",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestEventsAPISmoke",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002484829997229099,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0001802860001589579,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00021034500014138757,
            "outcome": "passed"
          }
        }
      ],
      "summary": {
        "passed": 6,
        "failed": 4,
        "total": 10,
        "collected": 20,
        "deselected": 10
      },
      "duration": 0.09281468391418457
    },
    "pipeline_tests": {
      "name": "Data Pipeline Tests",
      "status": "failed",
      "tests": [
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestDataPipelineBasic::test_pipeline_setup",
          "lineno": 79,
          "outcome": "passed",
          "keywords": [
            "test_pipeline_setup",
            "asyncio",
            "pytestmark",
            "TestDataPipelineBasic",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.020546683000247867,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00032876199975362397,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00022661299999526818,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestDataPipelineBasic::test_test_resource_creation",
          "lineno": 97,
          "outcome": "passed",
          "keywords": [
            "test_test_resource_creation",
            "asyncio",
            "pytestmark",
            "TestDataPipelineBasic",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003951799999413197,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00018641799988472485,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00020051699993928196,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPubSubIntegration::test_message_publishing",
          "lineno": 124,
          "outcome": "passed",
          "keywords": [
            "test_message_publishing",
            "asyncio",
            "pytestmark",
            "TestPubSubIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002443610001137131,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00018181600034949952,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00024583699996583164,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPubSubIntegration::test_bulk_message_publishing",
          "lineno": 151,
          "outcome": "failed",
          "keywords": [
            "test_bulk_message_publishing",
            "asyncio",
            "pytestmark",
            "TestPubSubIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00024584299990237923,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00020499699985521147,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 182,
              "message": "Failed: Bulk message publishing test failed: 'trafficEvent'"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 182,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestPubSubIntegration object at 0x7ffb9bc12d90>\n\n    @pytest.mark.asyncio\n    async def test_bulk_message_publishing(self):\n        \"\"\"Test publishing multiple messages to Pub/Sub.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic\n            topic_path = await test.create_test_topic()\n    \n            # Publish multiple test messages\n            test_events = [\n                test.test_data[\"events\"][\"validEvent\"],\n>               test.test_data[\"events\"][\"trafficEvent\"],\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n                test.test_data[\"events\"][\"environmentalEvent\"]\n            ]\nE           KeyError: 'trafficEvent'\n\nfeatures/data-pipeline/test_pipeline_e2e.py:166: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestPubSubIntegration object at 0x7ffb9bc12d90>\n\n    @pytest.mark.asyncio\n    async def test_bulk_message_publishing(self):\n        \"\"\"Test publishing multiple messages to Pub/Sub.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic\n            topic_path = await test.create_test_topic()\n    \n            # Publish multiple test messages\n            test_events = [\n                test.test_data[\"events\"][\"validEvent\"],\n                test.test_data[\"events\"][\"trafficEvent\"],\n                test.test_data[\"events\"][\"environmentalEvent\"]\n            ]\n    \n            message_ids = []\n            for event in test_events:\n                message_id = await test.publish_test_message(topic_path, event)\n                message_ids.append(message_id)\n    \n            assert len(message_ids) == 3\n            assert len(test.test_messages) == 3\n    \n            # Verify all messages have unique IDs\n            assert len(set(message_ids)) == 3\n    \n        except Exception as e:\n>           pytest.fail(f\"Bulk message publishing test failed: {str(e)}\")\nE           Failed: Bulk message publishing test failed: 'trafficEvent'\n\nfeatures/data-pipeline/test_pipeline_e2e.py:182: Failed"
          },
          "teardown": {
            "duration": 0.0003098649999628833,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestBigQueryIntegration::test_bigquery_data_validation",
          "lineno": 189,
          "outcome": "failed",
          "keywords": [
            "test_bigquery_data_validation",
            "asyncio",
            "pytestmark",
            "TestBigQueryIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002512389996809361,
            "outcome": "passed"
          },
          "call": {
            "duration": 1.0017251469998882,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 222,
              "message": "Failed: BigQuery validation test failed: assert False is True"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 222,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestBigQueryIntegration object at 0x7ffb9bc13950>\n\n    @pytest.mark.asyncio\n    async def test_bigquery_data_validation(self):\n        \"\"\"Test BigQuery data validation functionality.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic and publish message\n            topic_path = await test.create_test_topic()\n            test_message = test.test_data[\"events\"][\"validEvent\"]\n            await test.publish_test_message(topic_path, test_message)\n    \n            # Test data validation (with mock data since we don't have real pipeline)\n            expected_records = [test_message]\n    \n            # This would normally wait for pipeline processing\n            # For now, we'll test the validation logic itself\n            try:\n                # This will timeout since no real pipeline is running\n                # But it tests the validation framework\n                result = await asyncio.wait_for(\n                    test.validate_bigquery_data(\"events\", expected_records),\n                    timeout=5.0\n                )\n                # If we get here, validation worked (unlikely without real pipeline)\n>               assert result is True\nE               assert False is True\n\nfeatures/data-pipeline/test_pipeline_e2e.py:216: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestBigQueryIntegration object at 0x7ffb9bc13950>\n\n    @pytest.mark.asyncio\n    async def test_bigquery_data_validation(self):\n        \"\"\"Test BigQuery data validation functionality.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic and publish message\n            topic_path = await test.create_test_topic()\n            test_message = test.test_data[\"events\"][\"validEvent\"]\n            await test.publish_test_message(topic_path, test_message)\n    \n            # Test data validation (with mock data since we don't have real pipeline)\n            expected_records = [test_message]\n    \n            # This would normally wait for pipeline processing\n            # For now, we'll test the validation logic itself\n            try:\n                # This will timeout since no real pipeline is running\n                # But it tests the validation framework\n                result = await asyncio.wait_for(\n                    test.validate_bigquery_data(\"events\", expected_records),\n                    timeout=5.0\n                )\n                # If we get here, validation worked (unlikely without real pipeline)\n                assert result is True\n            except asyncio.TimeoutError:\n                # Expected - no real pipeline running\n                pass\n    \n        except Exception as e:\n>           pytest.fail(f\"BigQuery validation test failed: {str(e)}\")\nE           Failed: BigQuery validation test failed: assert False is True\n\nfeatures/data-pipeline/test_pipeline_e2e.py:222: Failed"
          },
          "teardown": {
            "duration": 0.0003069489998779318,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineE2EFlow::test_complete_pipeline_flow",
          "lineno": 229,
          "outcome": "passed",
          "keywords": [
            "test_complete_pipeline_flow",
            "slow",
            "asyncio",
            "pytestmark",
            "TestPipelineE2EFlow",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00031394299958265037,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002221750000899192,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00017329299998891656,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineErrorHandling::test_invalid_message_handling",
          "lineno": 251,
          "outcome": "passed",
          "keywords": [
            "test_invalid_message_handling",
            "asyncio",
            "pytestmark",
            "TestPipelineErrorHandling",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00030977400001575006,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00016631000016786857,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00016086099958556588,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineErrorHandling::test_resource_cleanup",
          "lineno": 274,
          "outcome": "passed",
          "keywords": [
            "test_resource_cleanup",
            "asyncio",
            "pytestmark",
            "TestPipelineErrorHandling",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00024088200007099658,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00016132599967022543,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00017872099988380796,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineSmoke::test_gcp_clients_initialization",
          "lineno": 303,
          "outcome": "passed",
          "keywords": [
            "test_gcp_clients_initialization",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestPipelineSmoke",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002063580000140064,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00014435699995374307,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0002508359998500964,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineSmoke::test_configuration_loading",
          "lineno": 325,
          "outcome": "failed",
          "keywords": [
            "test_configuration_loading",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestPipelineSmoke",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00021259899995129672,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002468520001457364,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 343,
              "message": "Failed: Configuration loading smoke test failed: assert 'database' in {'gcp': {'projectId': 'test-project'}}\n +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7ffb9bb1af10>.config"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 343,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestPipelineSmoke object at 0x7ffb9bc25a10>\n\n    @pytest.mark.smoke\n    @pytest.mark.asyncio\n    async def test_configuration_loading(self):\n        \"\"\"Smoke test: Configuration can be loaded.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            # Test configuration loading\n            assert test.config is not None\n            assert \"gcp\" in test.config\n>           assert \"database\" in test.config\nE           AssertionError: assert 'database' in {'gcp': {'projectId': 'test-project'}}\nE            +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7ffb9bb1af10>.config\n\nfeatures/data-pipeline/test_pipeline_e2e.py:336: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestPipelineSmoke object at 0x7ffb9bc25a10>\n\n    @pytest.mark.smoke\n    @pytest.mark.asyncio\n    async def test_configuration_loading(self):\n        \"\"\"Smoke test: Configuration can be loaded.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            # Test configuration loading\n            assert test.config is not None\n            assert \"gcp\" in test.config\n            assert \"database\" in test.config\n    \n            # Test data loading\n            assert test.test_data is not None\n            assert \"events\" in test.test_data\n    \n        except Exception as e:\n>           pytest.fail(f\"Configuration loading smoke test failed: {str(e)}\")\nE           Failed: Configuration loading smoke test failed: assert 'database' in {'gcp': {'projectId': 'test-project'}}\nE            +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7ffb9bb1af10>.config\n\nfeatures/data-pipeline/test_pipeline_e2e.py:343: Failed"
          },
          "teardown": {
            "duration": 0.00029972799984534504,
            "outcome": "passed"
          }
        }
      ],
      "summary": {
        "passed": 7,
        "failed": 3,
        "total": 10,
        "collected": 20,
        "deselected": 10
      },
      "duration": 1.0925605297088623
    },
    "frontend_tests": {
      "name": "Frontend Integration Tests",
      "status": "failed",
      "tests": [],
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0
      },
      "duration": 0,
      "note": "Minimal frontend testing - full implementation pending"
    },
    "performance_tests": {
      "name": "Performance Tests",
      "status": "failed",
      "tests": [],
      "summary": {},
      "duration": 0,
      "metrics": {
        "api_response_times": {},
        "throughput": {},
        "error_rates": {}
      }
    },
    "security_tests": {
      "name": "Security Tests",
      "status": "failed",
      "tests": [],
      "summary": {},
      "duration": 0
    }
  },
  "summary": {
    "total_tests": 20,
    "passed": 13,
    "failed": 7,
    "skipped": 0,
    "errors": 0
  },
  "performance_metrics": {},
  "coverage_report": {}
}
