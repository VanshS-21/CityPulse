{
  "environment": "test",
  "start_time": "2025-07-13T11:00:41.195625",
  "end_time": "2025-07-13T11:00:45.599194",
  "duration": 4.403567790985107,
  "suites": {
    "api_tests": {
      "name": "API Integration Tests",
      "status": "failed",
      "tests": [
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_create_event_success",
          "lineno": 60,
          "outcome": "passed",
          "keywords": [
            "test_create_event_success",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.04257539199999627,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003334310000013829,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0003878569999997694,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_create_event_validation_error",
          "lineno": 69,
          "outcome": "passed",
          "keywords": [
            "test_create_event_validation_error",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.000373899999999594,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00029569199999457396,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0002370790000014722,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPI::test_get_events_pagination",
          "lineno": 78,
          "outcome": "passed",
          "keywords": [
            "test_get_events_pagination",
            "asyncio",
            "pytestmark",
            "TestEventsAPI",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00034379799999584293,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002120949999948607,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00026839899999941963,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIIntegration::test_complete_event_lifecycle",
          "lineno": 91,
          "outcome": "failed",
          "keywords": [
            "test_complete_event_lifecycle",
            "asyncio",
            "pytestmark",
            "TestEventsAPIIntegration",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0002955699999986905,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00035886399999895957,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 114,
              "message": "Failed: Complete event lifecycle test failed: 'APITestBase' object has no attribute 'create_test_event'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 114,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIIntegration object at 0x7efc79d07310>\n\n    @pytest.mark.asyncio\n    async def test_complete_event_lifecycle(self):\n        \"\"\"Test complete event lifecycle from creation to cleanup.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            # Authenticate as citizen\n            await test.authenticate_user(\"citizen\")\n    \n            # Create test event\n            event_data = test.test_data[\"events\"][\"validEvent\"]\n>           created_event = await test.create_test_event(event_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'create_test_event'\n\nfeatures/events-management/test_events_api.py:104: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIIntegration object at 0x7efc79d07310>\n\n    @pytest.mark.asyncio\n    async def test_complete_event_lifecycle(self):\n        \"\"\"Test complete event lifecycle from creation to cleanup.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            # Authenticate as citizen\n            await test.authenticate_user(\"citizen\")\n    \n            # Create test event\n            event_data = test.test_data[\"events\"][\"validEvent\"]\n            created_event = await test.create_test_event(event_data)\n    \n            assert \"id\" in created_event\n            assert created_event[\"title\"] == event_data[\"title\"]\n            assert created_event[\"category\"] == event_data[\"category\"]\n    \n            # Cleanup\n            await test.cleanup_test_event(created_event[\"id\"])\n    \n        except Exception as e:\n>           pytest.fail(f\"Complete event lifecycle test failed: {str(e)}\")\nE           Failed: Complete event lifecycle test failed: 'APITestBase' object has no attribute 'create_test_event'\n\nfeatures/events-management/test_events_api.py:114: Failed"
          },
          "teardown": {
            "duration": 0.000270235000002117,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIIntegration::test_event_authentication_flows",
          "lineno": 117,
          "outcome": "passed",
          "keywords": [
            "test_event_authentication_flows",
            "asyncio",
            "pytestmark",
            "TestEventsAPIIntegration",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0004013549999939414,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00027738800000065567,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0002608580000043048,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIPerformance::test_api_response_times",
          "lineno": 152,
          "outcome": "failed",
          "keywords": [
            "test_api_response_times",
            "asyncio",
            "pytestmark",
            "TestEventsAPIPerformance",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003207779999954141,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003564550000021427,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 174,
              "message": "Failed: Performance test failed: 'APITestBase' object has no attribute 'generate_performance_report'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 174,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIPerformance object at 0x7efc79d106d0>\n\n    @pytest.mark.asyncio\n    async def test_api_response_times(self):\n        \"\"\"Test API response times are within acceptable limits.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test GET /events response time\n            response = await test.make_request(\"GET\", \"/events\")\n    \n            # Check performance metrics\n>           metrics = test.generate_performance_report()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'generate_performance_report'\n\nfeatures/events-management/test_events_api.py:166: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIPerformance object at 0x7efc79d106d0>\n\n    @pytest.mark.asyncio\n    async def test_api_response_times(self):\n        \"\"\"Test API response times are within acceptable limits.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test GET /events response time\n            response = await test.make_request(\"GET\", \"/events\")\n    \n            # Check performance metrics\n            metrics = test.generate_performance_report()\n    \n            if metrics.get(\"average_response_time\", 0) > 2.0:  # 2 second threshold\n                pytest.fail(f\"API response time too slow: {metrics['average_response_time']}s\")\n    \n            assert response.status_code == 200\n    \n        except Exception as e:\n>           pytest.fail(f\"Performance test failed: {str(e)}\")\nE           Failed: Performance test failed: 'APITestBase' object has no attribute 'generate_performance_report'\n\nfeatures/events-management/test_events_api.py:174: Failed"
          },
          "teardown": {
            "duration": 0.0002870269999988295,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIErrorHandling::test_invalid_event_id",
          "lineno": 181,
          "outcome": "failed",
          "keywords": [
            "test_invalid_event_id",
            "asyncio",
            "pytestmark",
            "TestEventsAPIErrorHandling",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00028818699999533237,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00027181000000098265,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 199,
              "message": "Failed: Error handling test failed: 'APITestBase' object has no attribute 'validate_error_response'"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 199,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIErrorHandling object at 0x7efc79d11190>\n\n    @pytest.mark.asyncio\n    async def test_invalid_event_id(self):\n        \"\"\"Test handling of invalid event IDs.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with invalid event ID\n            response = await test.make_request(\"GET\", \"/events/invalid-id\")\n            assert response.status_code == 404\n    \n            # Validate error response structure\n>           assert test.validate_error_response(response, 404, [\"error\", \"message\"])\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE           AttributeError: 'APITestBase' object has no attribute 'validate_error_response'\n\nfeatures/events-management/test_events_api.py:196: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIErrorHandling object at 0x7efc79d11190>\n\n    @pytest.mark.asyncio\n    async def test_invalid_event_id(self):\n        \"\"\"Test handling of invalid event IDs.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with invalid event ID\n            response = await test.make_request(\"GET\", \"/events/invalid-id\")\n            assert response.status_code == 404\n    \n            # Validate error response structure\n            assert test.validate_error_response(response, 404, [\"error\", \"message\"])\n    \n        except Exception as e:\n>           pytest.fail(f\"Error handling test failed: {str(e)}\")\nE           Failed: Error handling test failed: 'APITestBase' object has no attribute 'validate_error_response'\n\nfeatures/events-management/test_events_api.py:199: Failed"
          },
          "teardown": {
            "duration": 0.00039325500000586544,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPIErrorHandling::test_malformed_request_data",
          "lineno": 202,
          "outcome": "failed",
          "keywords": [
            "test_malformed_request_data",
            "asyncio",
            "pytestmark",
            "TestEventsAPIErrorHandling",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00030616000000094346,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00037077500000037844,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/events-management/test_events_api.py",
              "lineno": 220,
              "message": "Failed: Malformed data test failed: assert 200 == 400\n +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7efc79c1c290>.status_code"
            },
            "traceback": [
              {
                "path": "features/events-management/test_events_api.py",
                "lineno": 220,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_events_api.TestEventsAPIErrorHandling object at 0x7efc79d05990>\n\n    @pytest.mark.asyncio\n    async def test_malformed_request_data(self):\n        \"\"\"Test handling of malformed request data.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with malformed JSON\n            malformed_data = {\"title\": \"\", \"invalid_field\": \"test\"}\n            response = await test.make_request(\"POST\", \"/events\", data=malformed_data)\n    \n>           assert response.status_code == 400\nE           assert 200 == 400\nE            +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7efc79c1c290>.status_code\n\nfeatures/events-management/test_events_api.py:216: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_events_api.TestEventsAPIErrorHandling object at 0x7efc79d05990>\n\n    @pytest.mark.asyncio\n    async def test_malformed_request_data(self):\n        \"\"\"Test handling of malformed request data.\"\"\"\n        test = APITestBase()\n        await test.setup_client()\n    \n        try:\n            await test.authenticate_user(\"citizen\")\n    \n            # Test with malformed JSON\n            malformed_data = {\"title\": \"\", \"invalid_field\": \"test\"}\n            response = await test.make_request(\"POST\", \"/events\", data=malformed_data)\n    \n            assert response.status_code == 400\n            assert test.validate_error_response(response, 400)\n    \n        except Exception as e:\n>           pytest.fail(f\"Malformed data test failed: {str(e)}\")\nE           Failed: Malformed data test failed: assert 200 == 400\nE            +  where 200 = <test_events_api.APITestBase.make_request.<locals>.MockResponse object at 0x7efc79c1c290>.status_code\n\nfeatures/events-management/test_events_api.py:220: Failed"
          },
          "teardown": {
            "duration": 0.0002387070000011704,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPISmoke::test_events_endpoint_accessible",
          "lineno": 254,
          "outcome": "passed",
          "keywords": [
            "test_events_endpoint_accessible",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestEventsAPISmoke",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003628340000005892,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00021891600000145672,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00019784700000258226,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/events-management/test_events_api.py::TestEventsAPISmoke::test_authentication_works",
          "lineno": 271,
          "outcome": "passed",
          "keywords": [
            "test_authentication_works",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestEventsAPISmoke",
            "test_events_api.py",
            "e2e",
            "api",
            "events",
            "events-management",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00025417500000202153,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00022216200000002573,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0003148740000042949,
            "outcome": "passed"
          }
        }
      ],
      "summary": {
        "passed": 6,
        "failed": 4,
        "total": 10,
        "collected": 20,
        "deselected": 10
      },
      "duration": 0.13415002822875977
    },
    "pipeline_tests": {
      "name": "Data Pipeline Tests",
      "status": "failed",
      "tests": [
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestDataPipelineBasic::test_pipeline_setup",
          "lineno": 79,
          "outcome": "passed",
          "keywords": [
            "test_pipeline_setup",
            "asyncio",
            "pytestmark",
            "TestDataPipelineBasic",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.027259645000000887,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003566720000023338,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0004264660000004028,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestDataPipelineBasic::test_test_resource_creation",
          "lineno": 97,
          "outcome": "passed",
          "keywords": [
            "test_test_resource_creation",
            "asyncio",
            "pytestmark",
            "TestDataPipelineBasic",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0004007240000021284,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003029629999957706,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00025069499999830214,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPubSubIntegration::test_message_publishing",
          "lineno": 124,
          "outcome": "passed",
          "keywords": [
            "test_message_publishing",
            "asyncio",
            "pytestmark",
            "TestPubSubIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003277339999954165,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00023292700000610012,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0002381350000035809,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPubSubIntegration::test_bulk_message_publishing",
          "lineno": 151,
          "outcome": "failed",
          "keywords": [
            "test_bulk_message_publishing",
            "asyncio",
            "pytestmark",
            "TestPubSubIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00035249900000167145,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003743990000018016,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 182,
              "message": "Failed: Bulk message publishing test failed: 'trafficEvent'"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 182,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestPubSubIntegration object at 0x7f0bb4dca9d0>\n\n    @pytest.mark.asyncio\n    async def test_bulk_message_publishing(self):\n        \"\"\"Test publishing multiple messages to Pub/Sub.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic\n            topic_path = await test.create_test_topic()\n    \n            # Publish multiple test messages\n            test_events = [\n                test.test_data[\"events\"][\"validEvent\"],\n>               test.test_data[\"events\"][\"trafficEvent\"],\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n                test.test_data[\"events\"][\"environmentalEvent\"]\n            ]\nE           KeyError: 'trafficEvent'\n\nfeatures/data-pipeline/test_pipeline_e2e.py:166: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestPubSubIntegration object at 0x7f0bb4dca9d0>\n\n    @pytest.mark.asyncio\n    async def test_bulk_message_publishing(self):\n        \"\"\"Test publishing multiple messages to Pub/Sub.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic\n            topic_path = await test.create_test_topic()\n    \n            # Publish multiple test messages\n            test_events = [\n                test.test_data[\"events\"][\"validEvent\"],\n                test.test_data[\"events\"][\"trafficEvent\"],\n                test.test_data[\"events\"][\"environmentalEvent\"]\n            ]\n    \n            message_ids = []\n            for event in test_events:\n                message_id = await test.publish_test_message(topic_path, event)\n                message_ids.append(message_id)\n    \n            assert len(message_ids) == 3\n            assert len(test.test_messages) == 3\n    \n            # Verify all messages have unique IDs\n            assert len(set(message_ids)) == 3\n    \n        except Exception as e:\n>           pytest.fail(f\"Bulk message publishing test failed: {str(e)}\")\nE           Failed: Bulk message publishing test failed: 'trafficEvent'\n\nfeatures/data-pipeline/test_pipeline_e2e.py:182: Failed"
          },
          "teardown": {
            "duration": 0.0004050339999963626,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestBigQueryIntegration::test_bigquery_data_validation",
          "lineno": 189,
          "outcome": "failed",
          "keywords": [
            "test_bigquery_data_validation",
            "asyncio",
            "pytestmark",
            "TestBigQueryIntegration",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00031164700000374523,
            "outcome": "passed"
          },
          "call": {
            "duration": 1.0019219349999986,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 222,
              "message": "Failed: BigQuery validation test failed: assert False is True"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 222,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestBigQueryIntegration object at 0x7f0bb4dcb610>\n\n    @pytest.mark.asyncio\n    async def test_bigquery_data_validation(self):\n        \"\"\"Test BigQuery data validation functionality.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic and publish message\n            topic_path = await test.create_test_topic()\n            test_message = test.test_data[\"events\"][\"validEvent\"]\n            await test.publish_test_message(topic_path, test_message)\n    \n            # Test data validation (with mock data since we don't have real pipeline)\n            expected_records = [test_message]\n    \n            # This would normally wait for pipeline processing\n            # For now, we'll test the validation logic itself\n            try:\n                # This will timeout since no real pipeline is running\n                # But it tests the validation framework\n                result = await asyncio.wait_for(\n                    test.validate_bigquery_data(\"events\", expected_records),\n                    timeout=5.0\n                )\n                # If we get here, validation worked (unlikely without real pipeline)\n>               assert result is True\nE               assert False is True\n\nfeatures/data-pipeline/test_pipeline_e2e.py:216: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestBigQueryIntegration object at 0x7f0bb4dcb610>\n\n    @pytest.mark.asyncio\n    async def test_bigquery_data_validation(self):\n        \"\"\"Test BigQuery data validation functionality.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            await test.setup_clients()\n    \n            # Create test topic and publish message\n            topic_path = await test.create_test_topic()\n            test_message = test.test_data[\"events\"][\"validEvent\"]\n            await test.publish_test_message(topic_path, test_message)\n    \n            # Test data validation (with mock data since we don't have real pipeline)\n            expected_records = [test_message]\n    \n            # This would normally wait for pipeline processing\n            # For now, we'll test the validation logic itself\n            try:\n                # This will timeout since no real pipeline is running\n                # But it tests the validation framework\n                result = await asyncio.wait_for(\n                    test.validate_bigquery_data(\"events\", expected_records),\n                    timeout=5.0\n                )\n                # If we get here, validation worked (unlikely without real pipeline)\n                assert result is True\n            except asyncio.TimeoutError:\n                # Expected - no real pipeline running\n                pass\n    \n        except Exception as e:\n>           pytest.fail(f\"BigQuery validation test failed: {str(e)}\")\nE           Failed: BigQuery validation test failed: assert False is True\n\nfeatures/data-pipeline/test_pipeline_e2e.py:222: Failed"
          },
          "teardown": {
            "duration": 0.0005165159999975799,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineE2EFlow::test_complete_pipeline_flow",
          "lineno": 229,
          "outcome": "passed",
          "keywords": [
            "test_complete_pipeline_flow",
            "slow",
            "asyncio",
            "pytestmark",
            "TestPipelineE2EFlow",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0004063680000001568,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0002780209999997396,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0002384570000018016,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineErrorHandling::test_invalid_message_handling",
          "lineno": 251,
          "outcome": "passed",
          "keywords": [
            "test_invalid_message_handling",
            "asyncio",
            "pytestmark",
            "TestPipelineErrorHandling",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003332559999975615,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00020750400000224545,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00024947499999683487,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineErrorHandling::test_resource_cleanup",
          "lineno": 274,
          "outcome": "passed",
          "keywords": [
            "test_resource_cleanup",
            "asyncio",
            "pytestmark",
            "TestPipelineErrorHandling",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00026963999999907173,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003508679999981723,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.00022817199999991544,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineSmoke::test_gcp_clients_initialization",
          "lineno": 303,
          "outcome": "passed",
          "keywords": [
            "test_gcp_clients_initialization",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestPipelineSmoke",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.0003274100000041358,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.00019399899999683612,
            "outcome": "passed"
          },
          "teardown": {
            "duration": 0.0001961300000061783,
            "outcome": "passed"
          }
        },
        {
          "nodeid": "features/data-pipeline/test_pipeline_e2e.py::TestPipelineSmoke::test_configuration_loading",
          "lineno": 325,
          "outcome": "failed",
          "keywords": [
            "test_configuration_loading",
            "asyncio",
            "smoke",
            "pytestmark",
            "TestPipelineSmoke",
            "test_pipeline_e2e.py",
            "e2e",
            "pipeline",
            "gcp",
            "data-pipeline",
            "features",
            "e2e-tests",
            ""
          ],
          "setup": {
            "duration": 0.00026626700000065284,
            "outcome": "passed"
          },
          "call": {
            "duration": 0.0003121159999963652,
            "outcome": "failed",
            "crash": {
              "path": "/mnt/persist/workspace/e2e-tests/features/data-pipeline/test_pipeline_e2e.py",
              "lineno": 343,
              "message": "Failed: Configuration loading smoke test failed: assert 'database' in {'gcp': {'projectId': 'test-project'}}\n +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7f0bb4ad7f50>.config"
            },
            "traceback": [
              {
                "path": "features/data-pipeline/test_pipeline_e2e.py",
                "lineno": 343,
                "message": "Failed"
              }
            ],
            "longrepr": "self = <test_pipeline_e2e.TestPipelineSmoke object at 0x7f0bb4be18d0>\n\n    @pytest.mark.smoke\n    @pytest.mark.asyncio\n    async def test_configuration_loading(self):\n        \"\"\"Smoke test: Configuration can be loaded.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            # Test configuration loading\n            assert test.config is not None\n            assert \"gcp\" in test.config\n>           assert \"database\" in test.config\nE           AssertionError: assert 'database' in {'gcp': {'projectId': 'test-project'}}\nE            +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7f0bb4ad7f50>.config\n\nfeatures/data-pipeline/test_pipeline_e2e.py:336: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <test_pipeline_e2e.TestPipelineSmoke object at 0x7f0bb4be18d0>\n\n    @pytest.mark.smoke\n    @pytest.mark.asyncio\n    async def test_configuration_loading(self):\n        \"\"\"Smoke test: Configuration can be loaded.\"\"\"\n        test = DataPipelineE2ETest()\n    \n        try:\n            # Test configuration loading\n            assert test.config is not None\n            assert \"gcp\" in test.config\n            assert \"database\" in test.config\n    \n            # Test data loading\n            assert test.test_data is not None\n            assert \"events\" in test.test_data\n    \n        except Exception as e:\n>           pytest.fail(f\"Configuration loading smoke test failed: {str(e)}\")\nE           Failed: Configuration loading smoke test failed: assert 'database' in {'gcp': {'projectId': 'test-project'}}\nE            +  where {'gcp': {'projectId': 'test-project'}} = <test_pipeline_e2e.DataPipelineE2ETest object at 0x7f0bb4ad7f50>.config\n\nfeatures/data-pipeline/test_pipeline_e2e.py:343: Failed"
          },
          "teardown": {
            "duration": 0.00030974299999542154,
            "outcome": "passed"
          }
        }
      ],
      "summary": {
        "passed": 7,
        "failed": 3,
        "total": 10,
        "collected": 20,
        "deselected": 10
      },
      "duration": 1.1188023090362549
    },
    "frontend_tests": {
      "name": "Frontend Integration Tests",
      "status": "failed",
      "tests": [],
      "summary": {
        "total": 0,
        "passed": 0,
        "failed": 0
      },
      "duration": 0,
      "note": "Minimal frontend testing - full implementation pending"
    },
    "performance_tests": {
      "name": "Performance Tests",
      "status": "failed",
      "tests": [],
      "summary": {},
      "duration": 0,
      "metrics": {
        "api_response_times": {},
        "throughput": {},
        "error_rates": {}
      }
    },
    "security_tests": {
      "name": "Security Tests",
      "status": "failed",
      "tests": [],
      "summary": {},
      "duration": 0
    }
  },
  "summary": {
    "total_tests": 20,
    "passed": 13,
    "failed": 7,
    "skipped": 0,
    "errors": 0
  },
  "performance_metrics": {},
  "coverage_report": {}
}